#!/usr/bin/env python

__usage__ = "gpr_gpr [--options] proc.pkl [proc.pkl proc.pkl ...]"
__description__ = "read in existing processes from disk and generate another process over them."
__author__ = "reed.essick@ligo.org"

#---------------------------------------------------------------------------------------------------

import os

import numpy as np

from optparse import OptionParser

### non-standard
from universality import utils
from universality import gaussianprocess as gp
from universality import plot

#-------------------------------------------------

__default_min__ = 1e30 ### g/cm^3
__default_max__ = 1e38

__default_num__ = 51

__default_poly_degree__ = 1

__default_model_multiplier__ = 1

#-------------------------------------------------

def sanity_check_plot(x_tst, f_tst, std_tst, x_obs, f_obs, std_obs):
    '''
    a helper function for plotting regressions as a way to sanity check results
    '''
    xmin = np.min(x_tst)
    xmax = np.max(x_tst)

    fig = plot.plt.figure()
    foo = fig.add_axes([0.13, 0.30, 0.85, 0.65]) ### the actual data
    res = fig.add_axes([0.13, 0.10, 0.85, 0.19]) ### residuals between data

    ### plot the regression
    std_tst *= 3 ### plot 3-sigma region
    foo.fill_between(x_tst, f_tst-std_tst, f_tst+std_tst, color='grey', alpha=0.5)
    foo.plot(x_tst, f_tst, color='k')

    ylim = foo.get_ylim()

    res.fill_between(x_tst, -std_tst, +std_tst, color='grey', alpha=0.5)
    res.plot(x_tst, np.zeros_like(x_tst, dtype='int'), color='k')

    ### iterate through observed data and overlay
    for x, f, s in zip(x_obs, f_obs, std_obs):
        color = foo.plot(x, f, '.-', alpha=0.5)[0].get_color()

        s *= 3 ### plot 3-sigma region
        foo.fill_between(x, f+s, f-s, alpha=0.1, color=color)

        truth = (xmin<=x)*(x<=xmax)
        x = x[truth]
        f = f[truth]
        s = s[truth]
        f_int = np.interp(x, x_tst, f_tst)
        res.plot(x, f_int-f, '.-', color=color, alpha=0.5) ### plot the residual at the observed points
        res.fill_between(x, f_int-f-s, f_int-f+s, alpha=0.1, color=color)

    foo.set_ylim(ylim)

    ### decorate
    plot.plt.setp(foo.get_xticklabels(), visible=False)

    for ax in [foo, res]:
      ax.set_xlim(xmin=xmin, xmax=xmax)
      ax.grid(True, which='both')

    res.set_xlabel('$x$')
    res.set_ylabel(r'$f_\ast-f$')
    foo.set_ylabel('$f$')

    return fig, foo, res

#-------------------------------------------------

parser = OptionParser(usage=__usage__, description=__doc__)

parser.add_option('-v', '--verbose', default=False, action='store_true')

#--- options for evaluation
parser.add_option('', '--evaluate-bounds', default=(__default_min__, __default_max__), nargs=2, type='float',
    help='min max values for evaluation bounds. Specified in the same units used in the supplied pkl. \
DEFAULT=%.3e %.3e'%(__default_min__, __default_max__))
parser.add_option('', '--evaluate-num', default=__default_num__, type='int',
    help='evaluate at this number of points. \
DEFAULT=%d'%__default_num__)

parser.add_option('', '--evaluate-poly-degree', default=__default_poly_degree__, type='int',
    help='the degree of the polynomial used to model eos before GPR as part of evaluation. \
DEFAULT=%d'%__default_poly_degree__)

parser.add_option('', '--evaluate-sigma', default=gp.__default_sigma__, type='float',
    help='used as a guess for the optimizer. \
DEFAULT=%.3e'%gp.__default_sigma__)
parser.add_option('', '--evaluate-l', default=gp.__default_l__, type='float',
    help='used as a guess for the optimizer. \
DEFAULT=%.3e'%gp.__default_l__)
parser.add_option('', '--evaluate-sigma_obs', default=gp.__default_sigma__, type='float',
    help='used as a guess for the optimizer. \
DEFAULT=%.3e'%gp.__default_sigma__)

parser.add_option('', '--evaluate-model_multiplier', default=__default_model_multiplier__, type='float',
    help='multiplicative factor for theoretical variance. Larger values increase the "theory noise" from the variance between resampled curves. \
Default=%d'%__default_model_multiplier__)

#--- output options
parser.add_option('', '--plot', default=False, action='store_true',
    help='generate plots for altogether regression for sanity checking purposes')

parser.add_option('-o', '--output-dir', default='.', type='string')
parser.add_option('-t', '--tag', default='', type='string')

opts, args = parser.parse_args()
Npkl = len(args)
assert Npkl, 'please supply at least 1 input argument\n%s'%__usage__

if not os.path.exists(opts.output_dir):
    os.makedirs(opts.output_dir)

if opts.tag:
    opts.tag = "_"+opts.tag

#-------------------------------------------------

labels = None
means = []
covs = []
for pklpath in args:
    if opts.verbose:
        print('reading: '+pklpath)
    xlabel, ylabel, x, mean, cov = gp.pklload(pklpath)

    if labels==None:
        labels = xlabel, ylabel
        x_obs = x

    else:
        assert labels==(xlabel,ylabel), 'labels must match in all pkl files!'
        assert np.all(x_obs==x), 'all pkl files must be evaluated at the same x-values!'

    means.append(mean)
    covs.append(cov)

Nx = len(x_obs)

#-------------------------------------------------

if opts.verbose:
    print('computing modeling uncertainty at each x-value')

### reshape resampled vectors into 1D arrays
means_1d = np.concatenate(means)
xs_1d = np.concatenate([x_obs for _ in means])
Nobs = len(xs_1d)

### add in "theory model noise" as diagonal components based on variance of means at each pressure
covs_2d = np.zeros((Nobs,Nobs), dtype='float')

### iterate through pressure samples and compute theory variance of each
for i in xrange(Nx):
    ### variance for this pressure sample
    var = np.var([m[i] for m in means]) + np.sum([c[i,i] for c in covs])

    # multiply this sample by some factor (hyper-parameter)
    var *= opts.evaluate_model_multiplier

    # fill in big array as needed
    for j in xrange(Npkl):
        ind = j*Nx + i
        covs_2d[ind,ind] += var ### variance goes on the diagonal

### iterate over regression covariances and fill in the matrix
### this includes off-diagonal correlations within each resampling
i=0
for ind in xrange(Npkl):
    j = i+Nx
    covs_2d[i:j,i:j] += covs[ind]
    i = j

#-------------------------------------------------

### perform the "altogether" regression
if opts.verbose:
    print('evaluating f at %d points within [%.3e, %.3e] g/cm^3'%((opts.evaluate_num,)+opts.evaluate_bounds))
x_evaluate = np.linspace(
    opts.evaluate_bounds[0],
    opts.evaluate_bounds[1],
    opts.evaluate_num,
)

if opts.verbose:
    print('regressing %d values from %d noisy observations'%(opts.evaluate_num, Nobs))
mean, cov = gp.gpr_altogether(
    x_evaluate,
    means_1d,
    xs_1d,
    covs_2d,
    degree=opts.evaluate_poly_degree,
    guess_sigma2=opts.evaluate_sigma**2,
    guess_l2=opts.evaluate_l**2,
    guess_sigma2_obs=opts.evaluate_sigma_obs**2,
)

### save the result
pklpath = os.path.join(opts.output_dir, 'gpr_gpr%s.pkl'%opts.tag)
if opts.verbose:
    print('writing process to: '+pklpath)
gp.pkldump(pklpath, labels[0], labels[1], x_evaluate, mean, cov)

### plot the result
if opts.plot:
    figname = pklpath[:-3]+'png'
    if opts.verbose:
        print('saving: '+figname)
    fig, _, _ = sanity_check_plot(
        x_evaluate,
        mean,
        np.diag(cov)**0.5,
        [x_obs]*Npkl,
        means,
        [np.diag(c)**0.5 for c in covs],
    )
    fig.savefig(figname)
    plot.plt.close(fig)
