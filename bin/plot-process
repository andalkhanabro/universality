#!/usr/bin/env python

"""generate plots of processes from CSV files which refer to EOS tables (other csv files)
"""
__author__ = "Reed Essick (reed.essick@gmail.com)"

#-------------------------------------------------

import os
import glob
import numpy as np

from collections import defaultdict

from argparse import ArgumentParser

### non-standard libraries
from universality.utils import (utils, io, units)
from universality import plot
from universality import stats
from universality.kde import (logkde, silverman_bandwidth, vects2flatgrid)
from universality.properties import samples

#-------------------------------------------------

DEFAULT_EOS_COLUMN = 'EoS'
DEFAULT_EOS_DIR = '.'
DEFAULT_EOS_NUM_PER_DIR = 1000
DEFAULT_EOS_BASENAME = 'draw-foo-%d.csv'

#-------------------------------------------------

parser = ArgumentParser(description=__doc__)

# required arguments
rgroup = parser.add_argument_group('required arguments')
rgroup.add_argument('-s', '--samples', required=True, nargs=2, default=[], type=str, action='append',
    help='e.g.: "--samples label path/to/samples.csv"')

rgroup.add_argument('ycolumn', type=str)
rgroup.add_argument('xcolumn', type=str)

rgroup.add_argument('xmin', type=float)
rgroup.add_argument('xmax', type=float)

rgroup.add_argument('--y-multiplier', default=1, type=str,
    help='multiply all y-values by this before plotting. y-limits are applied after multiplying.')
rgroup.add_argument('--x-multiplier', default=1, type=str,
    help='multiply all x-values by this before plotting. x-limits are applied after multiplying.')

rgroup.add_argument('--default-y-value', default=None, type=float)

rgroup.add_argument('--overlay-samples', nargs=2, type=str, default=[], action='append',
    help='e.g. "--overlay-samples name samples.csv"')

# verbosity arguments
vgroup = parser.add_argument_group('verbosity arguments')
vgroup.add_argument('-v', '--verbose', default=False, action='store_true')
vgroup.add_argument('-V', '--Verbose', default=False, action='store_true')

# samples arguments
sgroup = parser.add_argument_group('samples-specific argument')
sgroup.add_argument('-m', '--max-num-samples', nargs=2, default=[], type=str, action='append',
    help='label max-num-samples pairs')
sgroup.add_argument('-w', '--weight-column', nargs=2, default=[], type=str, action='append',
    help='label column pairs. if provided, thie numerical values from this column will be used as weights in the KDE')
sgroup.add_argument('-W', '--weight-column-is-log', nargs=2, default=[], type=str, action='append',
    help='the label and column for samples for which this is true')

sgroup.add_argument('--overlay-xcolumn', nargs=2, default=[], type=str, action='append',
    help='e.g.: "--overlay-xcolumn name x"')
sgroup.add_argument('--overlay-ycolumn', nargs=2, default=[], type=str, action='append',
    help='e.g.: "--overlay-ycolumn name y"')

sgroup.add_argument('--overlay-column-bandwidth', nargs=3, default=[], type=str, action='append',
    help='e.g.: "--overlay-column-bandwidth name column 0.1"')

sgroup.add_argument('--overlay-weight-column', nargs=2, default=[], type=str, action='append',
    help='e.g.: "--overlay-weight-column name column"')
sgroup.add_argument('--overlay-weight-column-is-log', nargs=2, default=[], type=str, action='append',
    help='e.g.: "--overlay-weight-column name column"')
sgroup.add_argument('--overlay-invert-weight-column', nargs=2, default=[], type=str, action='append',
    help='e.g.: "--overlay-weight-column name column"')

# lookup arguments
lgroup = parser.add_argument_group('look-up arguments')
lgroup.add_argument('--eos-column', nargs=2, default=[], type=str, action='append',
    help='e.g.: "--eos-column label EoS')

lgroup.add_argument('--eos-dir', nargs=2, default=[], type=str, action='append',
    help='e.g.: "--eos-dir label path/to/directory"')
lgroup.add_argument('--eos-num-per-dir', nargs=2, default=[], type=str, action='append',
    help='a label and a string for the number of samples per directory')
lgroup.add_argument('--eos-basename', nargs=2, default=[], type=str, action='append',
    help='a label and a string into which the EOS number can be substituted when building filenames. NOTE, we glob for filenames, so if you wish to specify a subdirectory you can just provide the appropriate glob string and pick up everything underneath (useful for macroscopic properies of EOS).')

# workflow argumnets
wgroup = parser.add_argument_group('workflow arguments')
wgroup.add_argument('--num-points', default=101, type=int,
    help='the number of interpolation points used when plotting')
wgroup.add_argument('--num-draws', default=0, type=int,
    help='the number of fair draws to plot on top of the envelope')
wgroup.add_argument('--draw-from-weights', default=False, action='store_true',
    help='overlay fair draws from posterior with the same alpha instead of setting the alpha based on the weights')

wgroup.add_argument('--seed', default=None, type=int,
    help='the seed for numpy.random; allows for reproducible random draws')

# column arguments
cgroup = parser.add_argument_group('column-specific arguments')
cgroup.add_argument('-l', '--logcolumn', default=[], type=str, action='append',
    help='convert the values read in for this column to natural log. \
Can be repeated to specify multiple columns. \
DEFAULT=[]')
cgroup.add_argument('-L', '--column-label', nargs=2, default=[], type=str, action='append',
    help='replace the column name with this label in the corner plot. e.g.: \'xcol $x$\'. \
DEFAULT=[]')

# plotting options
pgroup = parser.add_argument_group('plotting options')

pgroup.add_argument('--reference', default=[], nargs=2, type=str, action='append',
    help='e.g.: "--reference name path". path to a reference CSV that will be plotted on top of the process plot. Can be repeated to specify multiple reference curves. \
The columns must be the same as those supplied in the input arguments. \
DEFAULT=[]')

pgroup.add_argument('--color', nargs=2, action='append', default=[], type=str,
    help='e.g. "--color label c"')
pgroup.add_argument('--truth-color', default=plot.DEFAULT_TRUTH_COLOR, type=str)
pgroup.add_argument('--reference-color', nargs=2, type=str, default=[], action='append',
    help='e.g.: "--reference-color name b"')

pgroup.add_argument('--quantile', default=[], type=float, action='append',
    help='plot these quantiles. \
DEFAULT=[0.9]')
pgroup.add_argument('--quantile-type', default='sym', type=str,
    help='the type of quantiles desired. Can be either "sym" or "hpd". \
If "sym", plots symmetric quantiles between (q, 1-q) for every quantile specified via --quantile. \
If "hpd", plots the highest-probability-density region for every quantile specified via --quantile, each of which may not be contiguous. \
DEFAULT="sym".')

pgroup.add_argument('--filled', default=False, action='store_true',
    help='fill in the region between quantiles')
pgroup.add_argument('--alpha', default=0.25, type=float,
    help='DEFAULT=0.25')
pgroup.add_argument('--draws-alpha', default=0.25, type=float,
    help='the alpha used when overlaying fair draws. DEFAULT=%.1f'%plot.DEFAULT_ALPHA)

pgroup.add_argument('--overlay-color', nargs=2, default=[], type=str, action='append',
    help='e.g.: "--overlay-color name blue"')
pgroup.add_argument('--overlay-alpha', nargs=2, default=[], type=str, action='append',
    help='e.g.: "--overlay-alpha name 0.5"')

pgroup.add_argument('--overlay-level', default=[], type=float, action='append',
    help='e.g.: "--overlay-level 0.9"')
pgroup.add_argument('--overlay-filled', default=False, action='store_true')
pgroup.add_argument('--overlay-num-points', default=101, type=int,
    help='the number of grid points used in the KDE overlays')

pgroup.add_argument('--residuals', default=False, action='store_true',
    help='if True, plot the residuals between the median of the process and the reference curves. Cannot be supplied simultanesoulsy with --ratios')
pgroup.add_argument('--ratios', default=False, action='store_true',
    help='if supplied, plot the ratio of the values instead of the difference (--residuals). Cannot be supplied simulaneously with --residuals')

pgroup.add_argument('--ymin', default=None, type=float)
pgroup.add_argument('--ymax', default=None, type=float)
pgroup.add_argument('--res-ymin', default=None, type=float)
pgroup.add_argument('--res-ymax', default=None, type=float)

pgroup.add_argument('--legend', default=False, action='store_true')
pgroup.add_argument('--include-neff', default=False, action='store_true',
    help='include an estimate of the effective number of samples as a title')

pgroup.add_argument('--reference-legend', default=False, action='store_true')

pgroup.add_argument('--figwidth', default=plot.DEFAULT_FIGWIDTH, type=float)
pgroup.add_argument('--figheight', default=plot.DEFAULT_FIGHEIGHT, type=float)

pgroup.add_argument('--grid', default=False, action='store_true')

# annotation options
agroup = parser.add_argument_group('annotation options')
agroup.add_argument('--signpost', nargs=2, default=[], type=str, action='append',
    help='add markers (vertical/horizontal lines) to denote specific values. e.g.: "baryon_density 2.7e14". Can be repeated')
agroup.add_argument('--signpost-color', default=plot.DEFAULT_TRUTH_COLOR, type=str)

# ouptut options
ogroup = parser.add_argument_group('output options')
ogroup.add_argument('-o', '--output-dir', default='.', type=str)
ogroup.add_argument('-t', '--tag', default='', type=str)
ogroup.add_argument('--figtype', default=[], type=str, action='append')
ogroup.add_argument('--dpi', default=plot.DEFAULT_DPI, type=float)

args = parser.parse_args()

### finish parsing

assert args.num_draws or args.quantile, 'must supply at least one --quantile or a nonzero --num-draws'

columns = [args.xcolumn, args.ycolumn]
names = [label for label, path in args.samples]
reference_names = [label for label, path in args.reference]
Nsamples = len(names)

logx = args.xcolumn in args.logcolumn
logy = args.ycolumn in args.logcolumn

# samples arguments
max_num_samples = dict((label, np.infty) for label in names)
for label, num in args.max_num_samples:
    assert label in names, 'specifying --max-num-sample for unknown sample set: '+label
    max_num_samples[label] = int(num)

weight_columns = dict((label, ([], [])) for label in names)
for label, column in args.weight_column:
    assert label in names, 'specifying --weight-column for unknown sample set: '+label
    weight_columns[label][0].append(column)

for label, column in args.weight_column_is_log:
    assert label in names, 'specifying --weight-column-is-log for unknown sample set: '+label
    weight_columns[label][1].append(column)

eos_dirs = dict((label, DEFAULT_EOS_DIR) for label in names)
for label, directory in args.eos_dir:
    assert label in names, 'specifying --eos-dir for unknown sample set: '+label
    eos_dirs[label] = directory

eos_num_per_dir = dict((label, DEFAULT_EOS_NUM_PER_DIR) for label in names)
for label, num in args.eos_num_per_dir:
    assert label in names, 'specifying --eos-num-per-dir for unknown sample set: '+label
    eos_num_per_dir[label] = int(num)

eos_basenames = dict((label, DEFAULT_EOS_BASENAME) for label in names)
for label, basename in args.eos_basename:
    assert label in names, 'specigying --eos-basename for unknown sample set: '+label
    eos_basenames[label] = basename

eos_temps = dict((label, os.path.join(eos_dirs[label], 'DRAWmod%d'%eos_num_per_dir[label]+'-%(moddraw)06d', eos_basenames[label])) for label in names)

eos_columns = dict((label, DEFAULT_EOS_COLUMN) for label in names)
for label, column in args.eos_column:
    assert label in names, 'specifying --eos-column for unknown sample set: '+label
    eos_columns[label] = column

# verbosity options
args.verbose |= args.Verbose

# column options
labels = dict((col, '$'+col+'$') for col in columns)
for column, label in args.column_label:
    assert column in columns, 'specifying --column-label for unknown column: '+column
    labels[column] = label

if isinstance(args.x_multiplier, str) and hasattr(units, args.x_multiplier):
    args.x_multiplier = getattr(units, args.x_multiplier)
else:
    args.x_multiplier = float(args.x_multiplier)

if isinstance(args.y_multiplier, str) and hasattr(units, args.y_multiplier):
    args.y_multiplier = getattr(units, args.y_multiplier)
else:
    args.y_multiplier = float(args.y_multiplier)

# plotting options
colors = dict((label, plot.DEFAULT_COLOR1) for label in names)
for label, color in args.color:
    assert label in names, 'specifying --color for uknown sample set: '+label
    colors[label] = color

reference_colors = dict((label, plot.DEFAULT_TRUTH_COLOR) for label in reference_names)
for label, color in args.reference_color:
    assert label in reference_names, 'specifying --reference-color for unknown reference set: '+label
    reference_colors[label] = color

if args.residuals and args.ratios:
    raise ValueError('please only supply either --residuals or --ratios')

if args.quantile_type not in ['sym', 'hpd']:
    raise ValueError('could not understand --quantile-type="%s", please specify either "sym" or "hpd".'%args.quantile_type)

if args.quantile:
    args.quantile.sort()

    if args.quantile_type=='sym':
        quantiles = []
        for q in args.quantile:
            quantiles += [q, (1-q)]
    else:
        quantiles = args.quantile
else:
    quantiles = []

Nquantiles = len(quantiles)
if args.quantile_type=="hpd":
    Nquantiles *= 2 ### we need twice as many as are in the list

# overlay KDE options
overlay_names = [a for a, b in args.overlay_samples] ### maintain order in which these were supplied
overlay_paths = dict(args.overlay_samples)

overlay_xcolumn = dict((name, args.xcolumn) for name in overlay_names)
for name, xcolumn in args.overlay_xcolumn:
    assert name in overlay_names, 'specifying --overlay-xcolumn for unknown overlay samples: '+name
    overlay_xcolumn[name] = xcolumn

overlay_ycolumn = dict((name, args.ycolumn) for name in overlay_names)
for name, ycolumn in args.overlay_ycolumn:
    assert name in overlay_names, 'specifying --overlay-ycolumn for unknown overlay samples: '+name
    overlay_ycolumn[name] = ycolumn

overlay_column_bandwidth = dict((name, {overlay_xcolumn[name]:None, overlay_ycolumn[name]:None}) for name in overlay_names)
for name, column, bandwidth in args.overlay_column_bandwidth:
    assert name in overlay_names, 'specifying --overlay-x-bandwidth for unknown overlay samples: '+name
    assert column in overlay_column_bandwidth[name], 'specfying --overlay-column-bandwidth for unknown column: '+column
    overlay_column_bandwidth[name][column] = float(bandwidth)

overlay_weight_column = dict((name, []) for name in overlay_names)
for name, column in args.overlay_weight_column:
    assert name in overlay_names, 'specifying --overlay-weight-column for unknown overlay samples: '+name
    overlay_weight_column[name].append(column)

overlay_weight_column_is_log = dict((name, []) for name in overlay_names)
for name, column in args.overlay_weight_column_is_log:
    assert name in overlay_names, 'specifying --overlay-weight-column-is-log for unknown overlay samples: '+name
    assert column in overlay_weight_column[name], 'specifying --overlay-weight-column-is-log for unkown column: '+column
    overlay_weight_column_is_log[name].append(column)

overlay_invert_weight_column = dict((name, []) for name in overlay_names)
for name, column in args.overlay_invert_weight_column:
    assert name in overlay_names, 'specifying --overlay-invert-weight-column for unknown overlay samples: '+name
    assert column in overlay_weight_column[name], 'specifying --overlay-invert-weight-column for unknown column: '+column
    overlay_invert_weight_column[name].append(column)

overlay_alpha = dict((name, plot.DEFAULT_ALPHA) for name in overlay_names)
for name, alpha in args.overlay_alpha:
    assert name in overlay_names, 'specifying --overlay-alpha for unknown overlay samples: '+name
    overlay_alpha[name] = float(alpha)

overlay_color = dict((name, plot.DEFAULT_COLOR3) for name in overlay_names)
for name, color in args.overlay_color:
    assert name in overlay_names, 'specifying --overlay-color for unknown overlay samples: '+name
    overlay_color[name] = color

if not args.overlay_level:
    args.overlay_level.append(0.9)
    if args.overlay_filled:
        args.overlay_level.append(0.90001)

# annotation options
signposts = defaultdict(list)
for column, value in args.signpost:
    assert column in columns, 'specifying --signpost for unknown column: '+column
    signposts[column].append(float(value))

# output options
if args.tag:
    args.tag = "_"+args.tag

if args.output_dir and (not os.path.exists(args.output_dir)):
    os.makedirs(args.output_dir)

if not args.figtype:
    args.figtype = plot.DEFAULT_FIGTYPES

#------------------------

### basic sanity-check for logarithmic plotting
if (args.default_y_value is not None) and (args.ycolumn in args.logcolumn):
    if (args.ymin is not None) and (args.default_y_value < args.ymin):
        args.default_y_value = args.ymin        

#-------------------------------------------------

if args.seed is not None:
    if args.verbose:
        print('setting numpy.random.seed to %d'%args.seed)
    np.random.seed(args.seed)

#-------------------------------------------------

# set up data
if logx:
    x_test = np.logspace(np.log10(args.xmin), np.log10(args.xmax), args.num_points)
else:
    x_test = np.linspace(args.xmin, args.xmax, args.num_points)

### iterate and plot
if args.legend and args.include_neff:
    neff = []
    nkde = []

if Nquantiles:
    y = np.empty((Nsamples, Nquantiles, args.num_points), dtype='float')
    y_median = np.empty((Nsamples, args.num_points), dtype='float')

if args.num_draws: ### curves to plot
    curves = []

for ind, (label, path) in enumerate(args.samples):
    if args.verbose:
        print('reading samples for %s from %s in: %s'%(label, eos_columns[label], path))
    data, cols = io.load(path, [eos_columns[label]], max_num_samples=max_num_samples[label])

    if weight_columns[label][0]:
        if args.verbose:
            print('reading in non-trivial weights from: '+path)
        weights = io.load_weights(path, weight_columns[label][0], logweightcolumns=weight_columns[label][1], max_num_samples=max_num_samples[label])

    else:
        N = len(data)
        weights = np.ones(N, dtype='float')/N

    ### marginalize to avoid reading in the same EOS more than once
    if args.verbose:
        print('marginalizing samples to avoid repeated work reading the same EoS multiple times')
    data, cols = utils.marginalize(data, np.log(weights), cols)
    weights = utils.exp_weights(data[:,cols.index('logmargweight')])
    data = data[:,0]

    ### prune samples to get rid of vanishing weights
    truth = weights > 0
    data = data[truth]
    weights = weights[truth]
    N = len(data)

    if args.legend and args.include_neff:
        neff.append(stats.neff(weights))
        nkde.append(stats.nkde(weights))

    #--------------------

    if Nquantiles:
        ### compute confidence regions
        if args.verbose:
            print('computing confidence intervals from %d samples'%N)

        qs, med = samples.process2quantiles(
            data,
            eos_temps[label],
            eos_num_per_dir[label],
            args.xcolumn,
            args.ycolumn,
            x_test,
            quantiles,
            quantile_type=args.quantile_type,
            x_multiplier=args.x_multiplier,
            y_multiplier=args.y_multiplier,
            weights=weights,
            default_y_value=args.default_y_value,
            verbose=args.Verbose,
        )

        y[ind,:,:] = qs
        y_median[ind,:] = med

    if args.num_draws: # draw curves from the process
        _curves = []
        _alphas = []

        if args.draw_from_weights: # fair draws from weights
            if args.verbose:
                print('drawing %d fair draws from the process, assigning each the same transparency'%args.num_draws)
            draws = utils.draw_from_weights(weights, size=args.num_draws)
            alphas = [args.draws_alpha]*len(draws)

        else:
            if args.verbose:
                print('drawing %d random draws from the sample set, assigning each a transparency proportional to their weight'%args.num_draws)
            draws = np.random.randint(0, high=len(data), size=args.num_draws)
            alphas = weights[draws]
            alphas *= args.draws_alpha / np.max(alphas)

        for draw, alpha in zip(draws, alphas):
            eos = data[draw]
            paths = sorted(glob.glob(eos_temps[label]%{'moddraw':eos//eos_num_per_dir[label], 'draw':eos}))
            for path in paths:
                if args.Verbose:
                    print('    loading: %s'%path)
                d, _ = io.load(path, [args.xcolumn, args.ycolumn])
                _curves.append((d[:,0]*args.x_multiplier, d[:,1]*args.y_multiplier, None))
                _alphas.append(alpha)

            if len(paths) and (args.default_y_value is not None) and np.any(x_test <= np.max(d[:,0]*args.x_multiplier)):
                X = x_test[x_test <= np.max(d[:,0]*args.x_multiplier)]
                Y = np.ones_like(X, dtype=float)*args.default_y_value
                _curves.append((X, Y, None))

        curves.append((label, _curves, _alphas))

### load in reference curves
reference = [] # define this out here so other loops can iterate over it even if we don't have any reference curves...
if args.reference:
    for label, path in args.reference:
        if args.verbose:
            print('reading reference curve from: '+path)
        d, _ = io.load(path, columns)
        d[:,0] *= args.x_multiplier
        d[:,1] *= args.y_multiplier
        reference.append((label, d)) ### just grab the data, not the column names

### set up reference curves
if args.residuals or args.ratios:
    if len(reference)==1: ### use the one reference curve a the baseline
        y_reference = np.interp(x_test, reference[0][1][:,0], reference[0][1][:,1])
        y_reference_label = 'reference'
    elif Nquantiles:
        y_reference = y_median[0,:]
        y_reference_label = 'median'
    else:
        y_reference = None
else:
    y_reference = None

#-------------------------------------------------

fig = None

if Nquantiles: ### plot quantiles from each posterior
    if args.verbose:
        print('plotting envelopes')

    fig= plot.envelope(
            x_test,
            y,
            y_median,
            names,
            colors,
            labels[args.xcolumn],
            labels[args.ycolumn],
            [args.xmin, args.xmax],
            legend=args.legend,
            neff_nkde=(neff, nkde) if (args.include_neff and args.legend) else None,
            logxcolumn=logx,
            logycolumn=logy,
            grid=args.grid,
            ymin=args.ymin,
            ymax=args.ymax,
            res_ymin=args.res_ymin,
            res_ymax=args.res_ymax,
            xsignposts=signposts[args.xcolumn],
            ysignposts=signposts[args.ycolumn],
            signpost_color=args.signpost_color,
            reference=reference,
            reference_colors=reference_colors,
            residuals=args.residuals,
            ratios=args.ratios,
            y_reference=y_reference,
            filled=args.filled,
            alpha=args.alpha,
            figwidth=args.figwidth,
            figheight=args.figheight,
    )

#------------------------

if args.num_draws: ### want to plot some fair draws from each posterior on top of the envelope
    if y_reference is not None:
        reference_curve = (x_test, y_reference)
    else:
        reference_curve = None

    if Nquantiles:
        ylims = []
        for ax in fig[1:]:
            ylims.append(ax.get_ylim())

    for label, draws, alphas in curves:
        if args.verbose:
            print('plotting draws for: %s'%label)
        fig = plot.overlay(
                draws,                
                colors=[colors[label]]*len(draws),
                alphas=alphas,
                logx=logx,
                logy=logy,
                reference_curve=reference_curve,
                residuals=args.residuals,
                ratios=args.ratios,
                figwidth=args.figwidth,
                figheight=args.figheight,
                figtup=fig,
            )

    if Nquantiles:
        for ax, ylim in zip(fig[1:], ylims):
            ax.set_xlim(xmin=args.xmin, xmax=args.xmax)
            ax.set_ylim(ylim)

    else:
        ### add reference curves
        if reference:
            fig = plot.overlay(
                [(x, y, label) for label, (x, y) in reference],
                colors=[colors[label] for label, _ in reference],
                logx=logx,
                logy=logy,
                reference_curve=reference_curve,
                residuals=args.residuals,
                ratios=args.ratios,
                figtup=fig,
            )
        
        ### annotate
        fig = plot.annotate_envelope(
            fig,
            names,
            colors,
            labels[args.xcolumn],
            labels[args.ycolumn],
            [args.xmin, args.xmax],
            legend=args.legend,
            neff_nkde=(neff, nkde) if (args.include_neff and args.legend) else None,
            logxcolumn=logx,
            logycolumn=logy,
            grid=args.grid,
            ymin=args.ymin,
            ymax=args.ymax,
            res_ymin=args.res_ymin,
            res_ymax=args.res_ymax,
            xsignposts=signposts[args.xcolumn],
            ysignposts=signposts[args.ycolumn],
            signpost_color=args.signpost_color,
            y_reference=y_reference,
            residuals=args.residuals,
            ratios=args.ratios,
        )

#------------------------

### overlay KDEs as needed
variances = np.empty(2, dtype=float)
vects = np.empty((2, args.overlay_num_points), dtype=float)

overlay_shape = (args.overlay_num_points, args.overlay_num_points)

YMIN, YMAX = fig[1].get_ylim()

for name in overlay_names:

    path = overlay_paths[name]
    xcolumn = overlay_xcolumn[name]
    ycolumn = overlay_ycolumn[name]

    # load samples
    if args.verbose:
        print('loading samples for overlay %s from: %s\n    xcolumn=%s\n    ycolumn=%s'%(name, path, xcolumn, ycolumn))

    logcolumns = []

    if logx:
        if args.Verbose:
            print('computing KDE overlay in logarithmic x-coordinates to match plot scale')
        logcolumns.append(xcolumn)

    if logy:
        if args.Verbose:
            print('computing KDE overlay in logarithmic y-coordinates to match plot scale')
        logcolumns.append(ycolumn)

    data, cols = io.load(path, [xcolumn, ycolumn], logcolumns=logcolumns)

    if overlay_weight_column[name]:
        if args.verbose:
            print('loading non-trivial weights from: %s'%path)
        weights = io.load_weights(
            path,
            overlay_weight_column[name],
            logweightcolumns=overlay_weight_column_is_log[name],
            invweightcolumns=overlay_invert_weight_column[name],
        )
    else:
        weights = np.ones(len(data), dtype=float)/len(data)

    # set up variances

    if overlay_column_bandwidth[name][xcolumn] is not None:
        variances[0] = overlay_column_bandwidth[name][xcolumn]
    else:
        variances[0] = silverman_bandwidth(data[:,0], weights=weights)
        if args.Verbose:
            print('automatically chose %s bandwidth=%.3e'%(cols[0], variances[0]))

    if overlay_column_bandwidth[name][ycolumn] is not None:
        variances[1] = overlay_column_bandwidth[name][ycolumn]
    else:
        variances[1] = silverman_bandwidth(data[:,1], weights=weights)
        if args.Verbose:
            print('automatically chose %s bandwidth=%.3e'%(cols[1], variances[1]))

    variances = variances**2

    # set up vects
    # need to figure out gridding so that we plot the PDF with the correct measure
    # this is based on whether each column was logged or not

    xmin, xmax = stats.samples2range(data[:,0])
    if logx:
        xmin = max(xmin, np.log(args.xmin))
        xmax = min(xmax, np.log(args.xmax))
    else:
        xmin = max(xmin, args.xmin)
        xmax = min(xmax, args.xmax)

    if args.Verbose:
        print('automatically chose %s range: %.3e, %.3e'%(cols[0], xmin, xmax))

    vects[0] = np.linspace(xmin, xmax, args.overlay_num_points)

    ymin, ymax = stats.samples2range(data[:,1])
    if logy:
        ymin = max(ymin, np.log(YMIN))
        ymax = min(ymax, np.log(YMAX))
    else:
        ymin = max(ymin, YMIN)
        ymax = min(ymax, YMAX)

    if args.Verbose:
        print('automatically chose %s range: %.3e, %.3e'%(cols[1], ymin, ymax))

    vects[1] = np.linspace(ymin, ymax, args.overlay_num_points)

    # compute and plot kde
    if args.Verbose:
        print('computing KDE')
    kde = logkde(
        vects2flatgrid(vects[0], vects[1]),
        data,
        variances,
    )
    kde = np.exp(kde-np.max(kde)).reshape(overlay_shape)
    # NOTE: we don't need to normalize the kde because that'll be taken care of within the call to stats.logkde2levels

    ### actually plot the contours

    # fix vects for plotting (ie, undo the fact that we computed the KDE in log coordinates)
    if logx:
        if args.Verbose:
            print('undoing log-transform for x-column before plotting')
        vects[0] = np.exp(vects[0])
    if logy:
        if args.Verbose:
            print('undoing log-transform for y-column before plotting')
        vects[1] = np.exp(vects[1])

    # figure out the thresholds for credible regions
    ### NOTE: the measure should be included in the grid placement, so this should give me the right levels
    thrs = sorted(np.exp(stats.logkde2levels(np.log(kde), args.overlay_level)), reverse=True)

    if args.Verbose:
        print('plotting KDE')

    if args.overlay_filled:
        fig[1].contourf(vects[0], vects[1], kde.transpose(), colors=overlay_color[name], alpha=overlay_alpha[name], levels=thrs)
    fig[1].contour(vects[0], vects[1], kde.transpose(), colors=overlay_color[name], alpha=overlay_alpha[name], levels=thrs)

#------------------------

# save
plot.save('plot-process%s'%args.tag, fig[0], directory=args.output_dir, figtypes=args.figtype, dpi=args.dpi, verbose=args.verbose)
plot.close(fig[0])
