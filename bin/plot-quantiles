#!/usr/bin/env python3

"""generate plots of quantiles extracted via process2quantiles
"""
__author__ = "Reed Essick (reed.essick@gmail.com)"

#-------------------------------------------------

import os
import re
import numpy as np

from collections import defaultdict

from argparse import ArgumentParser

### non-standard libraries
from universality.utils import (utils, io, units)
from universality import plot
from universality import stats
from universality.kde import (logkde, silverman_bandwidth, vects2flatgrid)
from universality.properties import samples

#-------------------------------------------------

parser = ArgumentParser(description=__doc__)

# required arguments
rgroup = parser.add_argument_group('required arguments')
rgroup.add_argument('-s', '--samples', required=True, nargs=2, default=[], type=str, action='append',
    help='e.g.: "--samples label path/to/samples.csv"')

rgroup.add_argument('xcolumn', type=str)
rgroup.add_argument('ycolumn', type=str)

rgroup.add_argument('xmin', type=float)
rgroup.add_argument('xmax', type=float)

rgroup.add_argument('--y-multiplier', default=1, type=str,
    help='multiply all y-values by this before plotting. y-limits are applied after multiplying.')
rgroup.add_argument('--x-multiplier', default=1, type=str,
    help='multiply all x-values by this before plotting. x-limits are applied after multiplying.')

rgroup.add_argument('--overlay-samples', nargs=2, type=str, default=[], action='append',
    help='e.g. "--overlay-samples name samples.csv"')

# verbosity arguments
vgroup = parser.add_argument_group('verbosity arguments')
vgroup.add_argument('-v', '--verbose', default=False, action='store_true')
vgroup.add_argument('-V', '--Verbose', default=False, action='store_true')

# column arguments
cgroup = parser.add_argument_group('column-specific arguments')
cgroup.add_argument('-l', '--logcolumn', default=[], type=str, action='append',
    help='convert the values read in for this column to natural log. \
Can be repeated to specify multiple columns. \
DEFAULT=[]')
cgroup.add_argument('-L', '--column-label', nargs=2, default=[], type=str, action='append',
    help='replace the column name with this label in the corner plot. e.g.: \'xcol $x$\'. \
DEFAULT=[]')

# workflow argumnets
wgroup = parser.add_argument_group('workflow arguments')
wgroup.add_argument('--num-points', default=101, type=int,
    help='the number of interpolation points used when plotting')

# samples arguments
sgroup = parser.add_argument_group('overlay samples arguments')

sgroup.add_argument('--overlay-xcolumn', nargs=2, default=[], type=str, action='append',
    help='e.g.: "--overlay-xcolumn name x"')
sgroup.add_argument('--overlay-ycolumn', nargs=2, default=[], type=str, action='append',
    help='e.g.: "--overlay-ycolumn name y"')

sgroup.add_argument('--overlay-column-bandwidth', nargs=3, default=[], type=str, action='append',
    help='e.g.: "--overlay-column-bandwidth name column 0.1"')

sgroup.add_argument('--overlay-weight-column', nargs=2, default=[], type=str, action='append',
    help='e.g.: "--overlay-weight-column name column"')
sgroup.add_argument('--overlay-weight-column-is-log', nargs=2, default=[], type=str, action='append',
    help='e.g.: "--overlay-weight-column name column"')
sgroup.add_argument('--overlay-invert-weight-column', nargs=2, default=[], type=str, action='append',
    help='e.g.: "--overlay-weight-column name column"')

# plotting options
pgroup = parser.add_argument_group('plotting options')

pgroup.add_argument('--reference', default=[], nargs=2, type=str, action='append',
    help='e.g.: "--reference name path". path to a reference CSV that will be plotted on top of the process plot. Can be repeated to specify multiple reference curves. \
The columns must be the same as those supplied in the input arguments. \
DEFAULT=[]')

pgroup.add_argument('--color', nargs=2, action='append', default=[], type=str,
    help='e.g. "--color label c"')
pgroup.add_argument('--truth-color', default=plot.DEFAULT_TRUTH_COLOR, type=str)
pgroup.add_argument('--reference-color', nargs=2, type=str, default=[], action='append',
    help='e.g.: "--reference-color name b"')

pgroup.add_argument('--overlay-color', nargs=2, default=[], type=str, action='append',
    help='e.g.: "--overlay-color name blue"')
pgroup.add_argument('--overlay-alpha', nargs=2, default=[], type=str, action='append',
    help='e.g.: "--overlay-alpha name 0.5"')

pgroup.add_argument('--overlay-no-scatter', default=False, action='store_true',
    help='do not plot the points from the overlay as a scatter')
pgroup.add_argument('--overlay-level', default=[], type=float, action='append',
    help='e.g.: "--overlay-level 0.9"')
pgroup.add_argument('--overlay-filled', default=False, action='store_true')
pgroup.add_argument('--overlay-num-points', default=101, type=int,
    help='the number of grid points used in the KDE overlays')

# other options

parser.add_argument('--quantile', default=[], type=float, action='append',
    help='plot these quantiles. \
DEFAULT=[0.9]')
parser.add_argument('--quantile-type', default='sym', type=str,
    help='the type of quantiles desired. Can be either "sym" or "hpd". \
If "sym", plots symmetric quantiles between (q, 1-q) for every quantile specified via --quantile. \
If "hpd", plots the highest-probability-density region for every quantile specified via --quantile, each of which may not be contiguous. \
DEFAULT="sym".')

parser.add_argument('--filled', default=[], type=str, action='append',
    help='fill in the region between quantiles')
parser.add_argument('--hatch', nargs=2, default=[], type=str, action='append')

parser.add_argument('--alpha', nargs=2, default=[], type=str, action='append')

parser.add_argument('--residuals', default=False, action='store_true',
    help='if True, plot the residuals between the median of the process and the reference curves. Cannot be supplied simultanesoulsy with --ratios')
parser.add_argument('--ratios', default=False, action='store_true',
    help='if supplied, plot the ratio of the values instead of the difference (--residuals). Cannot be supplied simulaneously with --residuals')

parser.add_argument('--ymin', default=None, type=float)
parser.add_argument('--ymax', default=None, type=float)
parser.add_argument('--res-ymin', default=None, type=float)
parser.add_argument('--res-ymax', default=None, type=float)

pgroup.add_argument('--legend', default=False, action='store_true')

pgroup.add_argument('--reference-legend', default=False, action='store_true')

pgroup.add_argument('--figwidth', default=plot.DEFAULT_FIGWIDTH, type=float)
pgroup.add_argument('--figheight', default=plot.DEFAULT_FIGHEIGHT, type=float)

pgroup.add_argument('--grid', default=False, action='store_true')

# annotation options
agroup = parser.add_argument_group('annotation options')
agroup.add_argument('--signpost', nargs=2, default=[], type=str, action='append',
    help='add markers (vertical/horizontal lines) to denote specific values. e.g.: "baryon_density 2.7e14". Can be repeated')
agroup.add_argument('--signpost-color', default=plot.DEFAULT_TRUTH_COLOR, type=str)

# ouptut options
ogroup = parser.add_argument_group('output options')
ogroup.add_argument('-o', '--output-dir', default='.', type=str)
ogroup.add_argument('-t', '--tag', default='', type=str)
ogroup.add_argument('--figtype', default=[], type=str, action='append')
ogroup.add_argument('--dpi', default=plot.DEFAULT_DPI, type=float)

args = parser.parse_args()

### finish parsing
columns = [args.xcolumn, args.ycolumn]
names = [label for label, path in args.samples]
reference_names = [label for label, path in args.reference]
Nsamples = len(names)

# verbosity options
args.verbose |= args.Verbose

# column options
labels = dict((col, '$'+col+'$') for col in columns)
for column, label in args.column_label:
    assert column in columns, 'specifying --column-label for unknown column: '+column
    labels[column] = label

if isinstance(args.x_multiplier, str) and hasattr(units, args.x_multiplier):
    args.x_multiplier = getattr(units, args.x_multiplier)
else:
    args.x_multiplier = float(args.x_multiplier)

if isinstance(args.y_multiplier, str) and hasattr(units, args.y_multiplier):
    args.y_multiplier = getattr(units, args.y_multiplier)
else:
    args.y_multiplier = float(args.y_multiplier)

logx = args.xcolumn in args.logcolumn
logy = args.ycolumn in args.logcolumn

# plotting options
colors = dict((label, plot.DEFAULT_COLOR1) for label in names)
for label, color in args.color:
    assert label in names, 'specifying --color for uknown sample set: '+label
    colors[label] = color

reference_colors = dict((label, plot.DEFAULT_TRUTH_COLOR) for label in reference_names)
for label, color in args.reference_color:
    assert label in reference_names, 'specifying --reference-color for unknown reference set: '+label
    reference_colors[label] = color

if args.residuals and args.ratios:
    raise ValueError('please only supply either --residuals or --ratios')

if args.quantile_type not in ['sym', 'hpd']:
    raise ValueError('could not understand --quantile-type="%s", please specify either "sym" or "hpd".'%args.quantile_type)

if not args.quantile:
    args.quantile = [0.9]
args.quantile.sort()

if args.quantile_type=='sym':
    quantiles = []
    for q in args.quantile:
        quantiles += [q, (1-q)]
else:
    quantiles = args.quantile

Nquantiles = len(quantiles)
if args.quantile_type=="hpd":
    Nquantiles *= 2 ### we need twice as many as are in the list

for label in args.filled:
    assert label in names, 'specifying --filled for unknown sample set: '+label

hatch = dict((label, None) for label in names)
for label, h in args.hatch:
    assert label in names, 'specifying --hatch for unknown sample set: '+label
    hatch[label] = h

alpha = dict((label, plot.DEFAULT_ALPHA) for label in names)
for label, a in args.alpha:
    assert label in names, 'specifying --alpha for unknown sample set: '+label
    alpha[label] = float(a)

# annotation options
signposts = defaultdict(list)
for column, value in args.signpost:
    assert column in columns, 'specifying --signpost for unknown column: '+column
    signposts[column].append(float(value))

# output options
if args.tag:
    args.tag = "_"+args.tag

if args.output_dir and (not os.path.exists(args.output_dir)):
    os.makedirs(args.output_dir)

if not args.figtype:
    args.figtype = plot.DEFAULT_FIGTYPES

# overlay KDE options
overlay_names = [a for a, b in args.overlay_samples] ### maintain order in which these were supplied
overlay_paths = dict(args.overlay_samples)

overlay_xcolumn = dict((name, args.xcolumn) for name in overlay_names)
for name, xcolumn in args.overlay_xcolumn:
    assert name in overlay_names, 'specifying --overlay-xcolumn for unknown overlay samples: '+name
    overlay_xcolumn[name] = xcolumn

overlay_ycolumn = dict((name, args.ycolumn) for name in overlay_names)
for name, ycolumn in args.overlay_ycolumn:
    assert name in overlay_names, 'specifying --overlay-ycolumn for unknown overlay samples: '+name
    overlay_ycolumn[name] = ycolumn

overlay_column_bandwidth = dict((name, {overlay_xcolumn[name]:None, overlay_ycolumn[name]:None}) for name in overlay_names)
for name, column, bandwidth in args.overlay_column_bandwidth:
    assert name in overlay_names, 'specifying --overlay-x-bandwidth for unknown overlay samples: '+name
    assert column in overlay_column_bandwidth[name], 'specfying --overlay-column-bandwidth for unknown column: '+column
    overlay_column_bandwidth[name][column] = float(bandwidth)

overlay_weight_column = dict((name, []) for name in overlay_names)
for name, column in args.overlay_weight_column:
    assert name in overlay_names, 'specifying --overlay-weight-column for unknown overlay samples: '+name
    overlay_weight_column[name].append(column)

overlay_weight_column_is_log = dict((name, []) for name in overlay_names)
for name, column in args.overlay_weight_column_is_log:
    assert name in overlay_names, 'specifying --overlay-weight-column-is-log for unknown overlay samples: '+name
    assert column in overlay_weight_column[name], 'specifying --overlay-weight-column-is-log for unkown column: '+column
    overlay_weight_column_is_log[name].append(column)

overlay_invert_weight_column = dict((name, []) for name in overlay_names)
for name, column in args.overlay_invert_weight_column:
    assert name in overlay_names, 'specifying --overlay-invert-weight-column for unknown overlay samples: '+name
    assert column in overlay_weight_column[name], 'specifying --overlay-invert-weight-column for unknown column: '+column
    overlay_invert_weight_column[name].append(column)

overlay_alpha = dict((name, plot.DEFAULT_ALPHA) for name in overlay_names)
for name, a in args.overlay_alpha:
    assert name in overlay_names, 'specifying --overlay-alpha for unknown overlay samples: '+name
    overlay_alpha[name] = float(a)

overlay_color = dict((name, plot.DEFAULT_COLOR3) for name in overlay_names)
for name, color in args.overlay_color:
    assert name in overlay_names, 'specifying --overlay-color for unknown overlay samples: '+name
    overlay_color[name] = color

if not args.overlay_level:
    args.overlay_level.append(0.9)
    if args.overlay_filled:
        args.overlay_level.append(0.90001)

#-------------------------------------------------

# set up data
if args.xcolumn in args.logcolumn:
    x_test = np.logspace(np.log10(args.xmin/args.x_multiplier), np.log10(args.xmax/args.x_multiplier), args.num_points)
else:
    x_test = np.linspace(args.xmin/args.x_multiplier, args.xmax/args.x_multiplier, args.num_points)

y = np.empty((Nsamples, Nquantiles, args.num_points), dtype='float')
y_median = np.empty((Nsamples, args.num_points), dtype='float')

### iterate and plot
pattern = re.compile(args.ycolumn + '\(' + args.xcolumn + '=(.*)\)') ### used to extract x-values

for ind, (label, path) in enumerate(args.samples):
    if args.verbose:
        print('reading quantiles for %s from: %s'%(label, path))
    data, cols = io.load(path)
    X = [float(pattern.match(col).group(1)) for col in cols[1:]] ### the x values at which we have quantiles
                                                                 ### assumes the first column is always "quantile"
    NX = len(X)

    #--------------------

    ### compute confidence regions
    if args.verbose:
        print('computing confidence intervals')

    # parse the column names
    if args.quantile_type == 'sym':
        for q_ind, q in enumerate(quantiles): ### iterate over requested quantiles
            ### interpolate to find the quantile at each X and then interpolate to map those onto x_test
            y[ind,q_ind,:] = np.interp(x_test, X, [np.interp(q, data[:,0], data[:,i+1]) for i in range(NX)])

    elif args.quantile_type == 'hpd':
        hpd = np.array([stats.cdf2crbounds(data[:,q_ind], data[:,0], quantiles) for q_ind in range(NX)]) ### compute HPD CR bounds
        for q_ind in range(Nquantiles/2):
            y[ind,2*q_ind] = np.interp(x_test, X, hpd[:,2*q_ind,0])
            y[ind,2*q_ind+1] = np.interp(x_test, X, hpd[:,2*q_ind,1])

    else:
        raise RuntimeError('--quantile-type=%s not understood'%args.quantile_type)
 
    # extract medians for each X and then interpolate
    y_median[ind,:] = np.interp(x_test, X, [np.interp(0.5, data[:,0], data[:,q_ind+1]) for q_ind in range(NX)])

### set things up for plotting
x_test *= args.x_multiplier
y *= args.y_multiplier
y_median *= args.y_multiplier

### load in reference curves
reference = [] # define this out here so other loops can iterate over it even if we don't have any reference curves...
if args.reference:
    for label, path in args.reference:
        if args.verbose:
            print('reading reference curve from: '+path)
        d, _ = io.load(path, columns)
        d[:,0] *= args.x_multiplier
        d[:,1] *= args.y_multiplier
        reference.append((label, d)) ### just grab the data, not the column names

### set up reference curves
if args.residuals or args.ratios:
    if len(reference)==1: ### use the one reference curve a the baseline
        y_reference = np.interp(x_test, reference[0][1][:,0], reference[0][1][:,1])
        y_reference_label = 'reference'
    else:
        y_reference = y_median[0,:]
        y_reference_label = 'median'

#-------------------------------------------------

if args.verbose:
    print('plotting')

fig = plot.envelope(
        x_test,
        y,
        y_median,
        names,
        colors,
        labels[args.xcolumn],
        labels[args.ycolumn],
        [args.xmin, args.xmax],
        legend=args.legend,
        logxcolumn=logx,
        logycolumn=logy,
        grid=args.grid,
        ymin=args.ymin,
        ymax=args.ymax,
        res_ymin=args.res_ymin,
        res_ymax=args.res_ymax,
        xsignposts=signposts[args.xcolumn],
        ysignposts=signposts[args.ycolumn],
        signpost_color=args.signpost_color,
        reference=reference,
        reference_colors=reference_colors,
        residuals=args.residuals,
        ratios=args.ratios,
        y_reference=y_reference if args.residuals or args.ratios else None,
        filled=args.filled,
        hatch=hatch,
        alphas=alpha,
        figwidth=args.figwidth,
        figheight=args.figheight,
)

### overlay KDEs as needed
variances = np.empty(2, dtype=float)
vects = np.empty((2, args.overlay_num_points), dtype=float)

overlay_shape = (args.overlay_num_points, args.overlay_num_points)

YMIN, YMAX = fig[1].get_ylim()

for name in overlay_names:

    path = overlay_paths[name]
    xcolumn = overlay_xcolumn[name]
    ycolumn = overlay_ycolumn[name]

    # load samples
    if args.verbose:
        print('loading samples for overlay %s from: %s\n    xcolumn=%s\n    ycolumn=%s'%(name, path, xcolumn, ycolumn))

    logcolumns = []

    data, cols = io.load(path, [xcolumn, ycolumn])
    data[:,0] *= args.x_multiplier
    data[:,1] *= args.y_multiplier

    if logx:
        if args.Verbose:
            print('computing KDE overlay in logarithmic x-coordinates to match plot scale')
        data[:,0] = np.log(data[:,0])

    if logy:
        if args.Verbose:
            print('computing KDE overlay in logarithmic y-coordinates to match plot scale')
        data[:,1] = np.log(data[:,1])

    if overlay_weight_column[name]:
        if args.verbose:
            print('loading non-trivial weights from: %s'%path)
        weights = io.load_weights(
            path,
            overlay_weight_column[name],
            logweightcolumns=overlay_weight_column_is_log[name],
            invweightcolumns=overlay_invert_weight_column[name],
        )
    else:
        weights = np.ones(len(data), dtype=float)/len(data)

    # throw away samples that have zero weight
    data = data[weights>0]
    weights = weights[weights>0]

    # set up variances

    if overlay_column_bandwidth[name][xcolumn] is not None:
        variances[0] = overlay_column_bandwidth[name][xcolumn]
    else:
        variances[0] = silverman_bandwidth(data[:,0], weights=weights)
        if args.Verbose:
            print('automatically chose %s bandwidth=%.3e'%(cols[0], variances[0]))

    if overlay_column_bandwidth[name][ycolumn] is not None:
        variances[1] = overlay_column_bandwidth[name][ycolumn]
    else:
        variances[1] = silverman_bandwidth(data[:,1], weights=weights)
        if args.Verbose:
            print('automatically chose %s bandwidth=%.3e'%(cols[1], variances[1]))

    variances = variances**2

    # set up vects
    # need to figure out gridding so that we plot the PDF with the correct measure
    # this is based on whether each column was logged or not

    xmin, xmax = stats.samples2range(data[:,0])
    if logx:
        xmin = max(xmin, np.log(args.xmin))
        xmax = min(xmax, np.log(args.xmax))
    else:
        xmin = max(xmin, args.xmin)
        xmax = min(xmax, args.xmax)

    if args.Verbose:
        print('automatically chose %s range: %.3e, %.3e'%(cols[0], xmin, xmax))

    vects[0] = np.linspace(xmin, xmax, args.overlay_num_points)

    ymin, ymax = stats.samples2range(data[:,1])
    if logy:
        ymin = max(ymin, np.log(YMIN))
        ymax = min(ymax, np.log(YMAX))
    else:
        ymin = max(ymin, YMIN)
        ymax = min(ymax, YMAX)

    if args.Verbose:
        print('automatically chose %s range: %.3e, %.3e'%(cols[1], ymin, ymax))

    vects[1] = np.linspace(ymin, ymax, args.overlay_num_points)

    # compute and plot kde
    if args.Verbose:
        print('computing KDE')
    kde = logkde(
        vects2flatgrid(vects[0], vects[1]),
        data,
        variances,
        weights=weights,
    )
    kde = np.exp(kde-np.max(kde)).reshape(overlay_shape)
    # NOTE: we don't need to normalize the kde because that'll be taken care of within the call to stats.logkde2levels

    ### actually plot the contours

    # fix vects for plotting (ie, undo the fact that we computed the KDE in log coordinates)
    if logx:
        if args.Verbose:
            print('undoing log-transform for x-column before plotting')
        vects[0] = np.exp(vects[0])
    if logy:
        if args.Verbose:
            print('undoing log-transform for y-column before plotting')
        vects[1] = np.exp(vects[1])

    # figure out the thresholds for credible regions
    ### NOTE: the measure should be included in the grid placement, so this should give me the right levels
    thrs = sorted(np.exp(stats.logkde2levels(np.log(kde), args.overlay_level)), reverse=True)

    if args.Verbose:
        print('plotting KDE contours')

    if args.overlay_filled:
        fig[1].contourf(vects[0], vects[1], kde.transpose(), colors=overlay_color[name], alpha=overlay_alpha[name], levels=thrs)
    fig[1].contour(vects[0], vects[1], kde.transpose(), colors=overlay_color[name], alpha=overlay_alpha[name], levels=thrs)

    if not args.overlay_no_scatter:
        if args.Verbose:
            print('plotting scatter')
        scatter_color = plot.weights2color(weights, overlay_color[name])

        if logx:
            data[:,0] = np.exp(data[:,0])
        if logy:
            data[:,1] = np.exp(data[:,1])

        fig[1].scatter(
            data[:,0],
            data[:,1],
            marker='o',
            s=2,
            color=scatter_color,
        )

### save

fig = fig[0]

plot.save('plot-quantiles%s'%args.tag, fig, directory=args.output_dir, figtypes=args.figtype, dpi=args.dpi, verbose=args.verbose)
plot.close(fig)
