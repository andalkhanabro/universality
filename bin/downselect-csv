#!/usr/bin/env python

__doc__ = "downselect a csv based on it's weights to generate a smaller, representative set"
__author__ = "Reed Essick <reed.essick@ligo.org>"

#-------------------------------------------------

import numpy as np

from argparse import ArgumentParser

### non-standard libraries
from universality import utils

#-------------------------------------------------

DEFAULT_NUM_SAMPLES = 10000

#-------------------------------------------------

parser = ArgumentParser(description=__doc__)

### required arguments
rgroup = parser.add_argument_group('required arguments')
rgroup.add_argument('sourcepath', type=str)
rgroup.add_argument('targetpath', type=str)
rgroup.add_argument('--weight-column', default=None, type=str)
rgroup.add_argument('--weight-column-is-log', default=False, action='store_true')

### verbosity arguments
vgroup = parser.add_argument_group('verbosity arguments')
vgroup.add_argument('-v', '--verbose', default=False, action='store_true')

### workflow arguments
wgroup = parser.add_argument_group('workflow arguments')
wgroup.add_argument('-n', '--num-samples', default=DEFAULT_NUM_SAMPLES, type=int,
    help='draw this many samples (with replacement) from the csv. \
DEFAULT=%d'%DEFAULT_NUM_SAMPLES)
wgroup.add_argument('-f', '--force', default=False, action='store_true',
    help='do not check the number of repeated samples and write the output regardless')

# finish parsing
args = parser.parse_args()

#-------------------------------------------------

if args.verbose:
    print('reading samples from: '+args.sourcepath)
data, columns = utils.load(args.sourcepath)

if args.weight_column is not None:
    try:
        ind = columns.index(args.weight_column)
    except ValueError:
        raise ValueError('--weight-column=%s not found!'%args.weight_column)
    weights = data[:,ind]

    if args.weight_column_is_log:
        weights = np.exp(weights-np.max(weights))
    weights /= np.sum(weights)

else:
    N = len(data)
    weights = np.ones(N, dtype=float)/N

### prune data that will never be selected
truth = weights > 0
data = data[truth]
weights = weights[truth]
N = len(data)

#------------------------

if args.verbose:
    print('drawing %d samples (with replacement)'%args.num_samples)

inds = utils.draw_from_weights(weights, size=args.num_samples)

if (not args.force) and (len(set(inds)) < 0.95*args.num_samples):
    raise RuntimeWarning('your subset has more than 5% repeated samples '+'(%d unique sample out of %d attempts). I do not think this is what you actually want. If it is, re-run with --force.'%(len(set(inds)), args.num_samples))

# keep only those data and get rid of the weights column
new = np.empty((args.num_samples, data.shape[1]), dtype=float)
new[...] = data[inds]
new[:,columns.index(args.weight_column)] = 1 ### set this so all weights are equal (prevent ourselves from double-counting weights)

#------------------------

if args.verbose:
    print('writing representative set to: '+args.targetpath)
with open(args.targetpath, 'w') as obj:
    print >> obj, ','.join(columns)
    tmp = ','.join('%.9e' for _ in xrange(new.shape[1]))
    for sample in new:
        print >> obj, tmp%tuple(sample)
