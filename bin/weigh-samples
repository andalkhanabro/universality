#!/usr/bin/env python

__doc__ = "a script that computes the associated weights for target_samples.csv based on the distribution within source_samples.csv."
__author__ = "reed.essick@ligo.org"
__usage__ = "weight_samples [--options] source_samples.csv target_samples.csv output_samples.csv column1 [column2 column3...]"

#-------------------------------------------------

import os

import numpy as np

from argparse import ArgumentParser

### non-standard libraries
from universality import utils

#-------------------------------------------------

parser = ArgumentParser(description=__doc__)

parser.add_argument('source', type=str)
parser.add_argument('target', type=str)
parser.add_argument('output', type=str)
parser.add_argument('columns', nargs='*', type=str)

parser.add_argument('-v', '--verbose', default=False, action='store_true')

parser.add_argument('--logcolumn', default=[], type=str, action='append',
    help='convert the values read in for this column to natural log. \
Can be repeated to specify multiple columns. \
DEFAULT=[]')

parser.add_argument('--weight-column', default=None, type=str,
    help='if provided, thie numerical values from this column will be used as weights in the KDE')
parser.add_argument('--weight-column-is-log', default=False, action='store_true',
    help='if supplied, interpret the values in weight_column as log(weight), meaning we exponentiate them before using them in the KDE')
parser.add_argument('--invert-weight-column', default=False, type=str,
    help='After extracting the weights from source_samples.csv, this will compute the KDE using the inverse of those values; e.g.: weight by the inverse of the prior for a set of posterior samples so the effective sampling is with respect to the likelihood. The inversion is done after exponentiation when --weight-column-is-log is supplied.')

parser.add_argument('-b', '--bandwidth', default=0.03, type=float,
    help='the bandwidth (standard deviation) used within the Gaussian KDE over whitened data. \
DEFAULT=0.03')

parser.add_argument('--num-proc', default=utils.DEFAULT_NUM_PROC, type=int,
    help='number of processes for parallelized computation of logkde. \
DEFAULT=%d'%utils.DEFAULT_NUM_PROC)

args = parser.parse_args()
Ncol = len(args.columns)

#-------------------------------------------------

### read in source samples
if args.verbose:
    print('reading source samples from: '+args.source)
srcdata, columns = utils.load(args.source, args.columns, logcolumns=args.logcolumn)
srcdata, srcmeans, srcstds = utils.whiten(srcdata, verbose=args.verbose) ### whiten data

if args.weight_column!=None:
    if args.verbose:
        print('reading in non-trivial weights from: '+args.source)
    weights, _ = utils.load(args.source, [args.weight_column])
    weights = weights.flatten()

    if args.weight_column_is_log:
        weights = np.exp(weights-np.max(weights))
    weights /= np.sum(weights)

    if args.invert_weight_column:
        weights = 1./weights

else:
    weights = None

#------------------------

### read in target samples
if args.verbose:
    print("reading in target samples from: "+args.target)
tgtdata, tgtcolumns = utils.load(args.target, logcolumns=args.logcolumn) ### load in all the columns!
utils.check_columns(tgtcolumns, args.columns) ### make sure we have the columns we need to

tgtsamples = np.empty((len(tgtdata), Ncol), dtype='float')
for i, column in enumerate(columns): ### whiten the target data with the same transformation used for source data
    tgtsamples[:,i] = (tgtdata[:,tgtcolumns.index(column)] - srcmeans[i])/srcstds[i]

#-------------------------------------------------

if args.verbose:
    print('computing weighted KDE at %d samples from %s based on %d samples from %s with %d cores'%(len(tgtsamples), args.target, len(srcdata), args.source, args.num_proc))
logkde = utils.logkde(tgtsamples, srcdata, np.ones(Ncol, dtype=float)*args.bandwidth**2, weights=weights, num_proc=args.num_proc)

if args.verbose:
    print('writing results into: '+args.output)

template = ','.join('%.9e' for _ in xrange(len(tgtcolumns)+1))
with open(args.output, 'w') as file_obj:
    print >> file_obj, ','.join(tgtcolumns+['logweights'])
    for sample, logweight in zip(tgtdata, logkde):
        print >> file_obj, template%tuple(list(sample)+[logweight])
