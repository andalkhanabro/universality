#!/usr/bin/env python3

"""a script that computes the associated weights for target_samples.csv based on the distribution within source_samples.csv.
"""
__author__ = "Reed Essick (reed.essick@gmail.com)"

#-------------------------------------------------

import numpy as np

from argparse import ArgumentParser

### non-standard libraries
from universality.utils import (utils, io)
from universality import kde

#-------------------------------------------------

parser = ArgumentParser(description=__doc__)

parser.add_argument('source', type=str)
parser.add_argument('target', type=str)
parser.add_argument('output', type=str)
parser.add_argument('columns', nargs='+', type=str)

parser.add_argument('-v', '--verbose', default=False, action='store_true')

parser.add_argument('--logcolumn', default=[], type=str, action='append',
    help='convert the values read in for this column to natural log. \
Can be repeated to specify multiple columns. \
DEFAULT=[]')

parser.add_argument('--weight-column', default=[], type=str, action='append',
    help='if provided, thie numerical values from this column will be used as weights in the KDE')
parser.add_argument('--weight-column-is-log', default=[], type=str, action='append',
    help='if supplied, interpret the values in weight_column as log(weight), meaning we exponentiate them before using them in the KDE')
parser.add_argument('--invert-weight-column', default=[], type=str, action='append',
    help='After extracting the weights from source_samples.csv, this will compute the KDE using the inverse of those values; e.g.: weight by the inverse of the prior for a set of posterior samples so the effective sampling is with respect to the likelihood. The inversion is done after exponentiation when --weight-column-is-log is supplied.')

parser.add_argument('-r', '--column-range', nargs=3, default=[], action='append', type=str,
    help='specify the ranges used in corner.corner (eg.: "--column-range column minimum maximum"). \
Can specify ranges for multiple columns by repeating this option. \
DEFAULT will use the minimum and maximum observed sample points.')
parser.add_argument('--reflect', default=False, action='store_true',
    help='reflect the points about their boundaries within the KDE')
parser.add_argument('--prune', default=False, action='store_true',
    help='throw away samples that live outside the specified ranges')

parser.add_argument('--output-weight-column', default=utils.DEFAULT_WEIGHT_COLUMN, type=str,
    help='the name of the new weight-column in the output file. **BE CAREFUL!** You should make sure this is consistent with whether or not you specified --do-not-log-output-weight! \
DEFAULT='+utils.DEFAULT_WEIGHT_COLUMN)
parser.add_argument('--do-not-log-output-weights', default=False, action='store_true',
    help='record the raw weights instead of the log(weight) in the output CVS. **BE CAREFUL!** You should make sure this is consistent with the name specified by --output-weight-column.')

parser.add_argument('-b', '--bandwidth', default=0.03, type=float,
    help='the bandwidth (standard deviation) used within the Gaussian KDE over whitened data. \
DEFAULT=0.03')

parser.add_argument('--num-proc', default=utils.DEFAULT_NUM_PROC, type=int,
    help='number of processes for parallelized computation of logkde. \
DEFAULT=%d'%utils.DEFAULT_NUM_PROC)

args = parser.parse_args()
Ncol = len(args.columns)

### parse ranges
rangesdict = dict()
for column, _min, _max in args.column_range:
    assert column in args.columns, 'specifying --column-range for unknown column: '+column
    rangesdict[column] = (float(_min), float(_max))

#-------------------------------------------------

### read in source samples
if args.verbose:
    print('reading source samples from: '+args.source)
srcdata, columns = io.load(args.source, args.columns, logcolumns=args.logcolumn)
if not len(srcdata):
    raise RuntimeError('no samples present in %s!'%args.source)
srcdata, srcmeans, srcstds = utils.whiten(srcdata, verbose=args.verbose) ### whiten data

if args.weight_column:
    if args.verbose:
        print('reading in non-trivial weights from: '+args.source)
    weights = io.load_weights(args.source, args.weight_column, logweightcolumns=args.weight_column_is_log, invweightcolumns=args.invert_weight_column)

else:
    N = len(srcdata)
    weights = np.ones(N, dtype=float)/N

### figure out ranges based on data
ranges = []
for i, col in enumerate(columns):
    if rangesdict.has_key(col):
        m, M = rangesdict[col]
        ranges.append(((m-srcmeans[i])/srcstds[i], (M-srcmeans[i])/srcstds[i]))
    else:
        ranges.append(None)

if args.prune:
    srcdata, weights = utils.prune(srcdata, ranges, weights=weights)

if args.reflect:
    srcdata, weights = utils.reflect(srcdata, ranges, weights=weights)

#------------------------

### read in target samples
if args.verbose:
    print("reading in target samples from: "+args.target)
tgtdata, tgtcolumns = io.load(args.target, logcolumns=args.logcolumn) ### load in all the columns!
io.check_columns(tgtcolumns, args.columns, logcolumns=args.logcolumn) ### make sure we have the columns we need to

if len(tgtdata): ### we need to weigh things

    tgtsamples = np.empty((len(tgtdata), Ncol), dtype='float')
    for i, column in enumerate(columns): ### whiten the target data with the same transformation used for source data
        tgtsamples[:,i] = (tgtdata[:,tgtcolumns.index(column)] - srcmeans[i])/srcstds[i]

    #---------------------------------------------

    if args.verbose:
        print('computing weighted KDE at %d samples from %s based on %d samples from %s with %d cores'%\
            (len(tgtsamples), args.target, len(srcdata), args.source, args.num_proc))
    logkde = kde.logkde(
        tgtsamples,
        srcdata,
        np.ones(Ncol, dtype=float)*args.bandwidth**2,
        weights=weights,
        num_proc=args.num_proc
    )
else:
    if args.verbose:
        print('no target samples in %s; nothing to do...'%args.target)
    logkde = np.empty(0, dtype=float) ### make a place-holder so the rest of the logic holds

if args.do_not_log_output_weights:
    if args.verbose:
        print('exponentiating weights')
    logkde = np.exp(logkde)

if args.verbose:
    print('writing results with weight-column=%s into: %s'%(args.output_weight_column, args.output))

### undo logcolumn formatting if needed
for column in args.logcolumn:
    i = tgtcolumns.index(io.column2logcolumn(column))
    tgtdata[:,i] = np.exp(tgtdata[:,i])
    tgtcolumns[i] = column

### now actually write stuff to disk
atad = np.empty((len(tgtdata), len(tgtcolumns)+1), dtype=float)
atad[:,:-1] = tgtdata
atad[:,-1] = logkde
io.write(args.output, atad, tgtcolumns+[args.output_weight_column])
