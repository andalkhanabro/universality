#!/usr/bin/env python

__description__ = "read in existing processes from disk and generate another process over them."
__author__ = "reed.essick@ligo.org"

#---------------------------------------------------------------------------------------------------

import os

import numpy as np

from argparse import ArgumentParser

### non-standard
from universality import utils
from universality import gaussianprocess as gp
from universality import plot

#-------------------------------------------------

DEFAULT_MIN = 1e30 ### g/cm^3
DEFAULT_MAX = 1e38

#-------------------------------------------------

parser = ArgumentParser(description=__doc__)

### required arguments
parser.add_argument_group('required arguments')
parser.add_argument('pklpaths', nargs='+', type=str)

### verbosity options
vgroup = parser.add_argument_group('verbosity arguments')
parser.add_argument('-v', '--verbose', default=False, action='store_true')

### options for evaluation
ggroup = parser.add_argument_group('Gaussian Process options')
ggroup.add_argument('--evaluate-bounds', default=(DEFAULT_MIN, DEFAULT_MAX), nargs=2, type=float,
    help='min max values for evaluation bounds. Specified in the same units used in the supplied pkl. \
DEFAULT=%.3e %.3e'%(DEFAULT_MIN, DEFAULT_MAX))
ggroup.add_argument('--evaluate-num', default=gp.DEFAULT_NUM, type=int,
    help='evaluate at this number of points. \
DEFAULT=%d'%gp.DEFAULT_NUM)

ggroup.add_argument('--evaluate-poly-degree', default=gp.DEFAULT_POLY_DEGREE, type=int,
    help='the degree of the polynomial used to model eos before GPR as part of evaluation. \
DEFAULT=%d'%gp.DEFAULT_POLY_DEGREE)

ggroup.add_argument('--evaluate-sigma', default=gp.DEFAULT_SIGMA, type=float,
    help='used as a guess for the optimizer. \
DEFAULT=%.3e'%gp.DEFAULT_SIGMA)
ggroup.add_argument('--evaluate-l', default=gp.DEFAULT_L, type=float,
    help='used as a guess for the optimizer. \
DEFAULT=%.3e'%gp.DEFAULT_L)
ggroup.add_argument('--evaluate-sigma_obs', default=gp.DEFAULT_SIGMA, type=float,
    help='used as a guess for the optimizer. \
DEFAULT=%.3e'%gp.DEFAULT_SIGMA)

ggroup.add_argument('--evaluate-model_multiplier', default=gp.DEFAULT_MODEL_MULTIPLIER, type=float,
    help='multiplicative factor for theoretical variance. Larger values increase the "theory noise" from the variance between resampled curves. \
Default=%d'%gp.DEFAULT_MODEL_MULTIPLIER)

### plotting options
pgroup = parser.add_argument_group('plotting options')
pgroup.add_argument('-p', '--plot', default=False, action='store_true')
pgroup.add_argument('--residuals', default=False, action='store_true')

pgroup.add_argument('--ylabel', default='$\phi$', type=str)

pgroup.add_argument('--figwidth', default=plot.DEFAULT_FIGWIDTH, type=float)
pgroup.add_argument('--figheight', default=plot.DEFAULT_FIGHEIGHT, type=float)

### output options
ogroup = parser.add_argument_group('output options')
ogroup.add_argument('-o', '--output-dir', default='.', type=str)
ogroup.add_argument('-t', '--tag', default='', type=str)
ogroup.add_argument('--figtype', default=[], type=str, action='append')
ogroup.add_argument('--dpi', default=plot.DEFAULT_DPI, type=float)

args = parser.parse_args()
Npkl = len(args.pklpaths)

if not os.path.exists(args.output_dir):
    os.makedirs(args.output_dir)

if args.tag:
    args.tag = "_"+args.tag

#-------------------------------------------------

labels = None
means = []
covs = []
for pklpath in args.pklpaths:
    if args.verbose:
        print('reading: '+pklpath)
    xlabel, ylabel, x, mean, cov = gp.pklload(pklpath)

    if labels==None:
        labels = xlabel, ylabel
        x_obs = x

    else:
        assert labels==(xlabel,ylabel), 'labels must match in all pkl files!'
        assert np.all(x_obs==x), 'all pkl files must be evaluated at the same x-values!'

    means.append(mean)
    covs.append(cov)

Nx = len(x_obs)

#-------------------------------------------------

if args.verbose:
    print('computing modeling uncertainty at each x-value')

### reshape resampled vectors into 1D arrays
means_1d = np.concatenate(means)
xs_1d = np.concatenate([x_obs for _ in means])
Nobs = len(xs_1d)

### add in "theory model noise" as diagonal components based on variance of means at each pressure
covs_2d = np.zeros((Nobs,Nobs), dtype='float')

### iterate through pressure samples and compute theory variance of each
for i in xrange(Nx):
    ### variance for this pressure sample
    var = np.var([m[i] for m in means]) + np.sum([c[i,i] for c in covs])

    # multiply this sample by some factor (hyper-parameter)
    var *= args.evaluate_model_multiplier

    # fill in big array as needed
    for j in xrange(Npkl):
        ind = j*Nx + i
        covs_2d[ind,ind] += var ### variance goes on the diagonal

### iterate over regression covariances and fill in the matrix
### this includes off-diagonal correlations within each resampling
i=0
for ind in xrange(Npkl):
    j = i+Nx
    covs_2d[i:j,i:j] += covs[ind]
    i = j

#-------------------------------------------------

### perform the "altogether" regression
if args.verbose:
    print('evaluating f at %d points within [%.3e, %.3e] g/cm^3'%((args.evaluate_num,)+args.evaluate_bounds))
x_evaluate = np.linspace(
    args.evaluate_bounds[0],
    args.evaluate_bounds[1],
    args.evaluate_num,
)

if args.verbose:
    print('regressing %d values from %d noisy observations'%(args.evaluate_num, Nobs))
mean, cov = gp.gpr_altogether(
    x_evaluate,
    means_1d,
    xs_1d,
    covs_2d,
    degree=args.evaluate_poly_degree,
    guess_sigma2=args.evaluate_sigma**2,
    guess_l2=args.evaluate_l**2,
    guess_sigma2_obs=args.evaluate_sigma_obs**2,
)

### save the result
pklpath = os.path.join(args.output_dir, 'gpr_gpr%s.pkl'%args.tag)
if args.verbose:
    print('writing process to: '+pklpath)
gp.pkldump(pklpath, labels[0], labels[1], x_evaluate, mean, cov)

### plot the result
if args.plot:
    cr_obs = []
    for mean, cov in zip(means, covs):
        cov = np.diag(cov)**0.5
        cr_obs.append( (mean-cov, mean+cov) )

    fig = plot.gpr_overlay(
        np.exp(x_evaluate),
        mean,
        (mean-np.diag(cov)**0.5, mean+np.diag(cov)**0.5),
        [np.exp(x_obs) for _ in range(Npkl)],
        means,
        cr_obs=cr_obs,
        logx=True,
        logy=False,
        xlabel='$p/c^2$',
        ylabel=args.ylabel,
        residuals=args.residuals,
        figwidth=args.figwidth,
        figheight=args.figheight,
    )
    plot.save('gpr-gpr%s'%args.tag, fig, figtypes=args.figtype, directory=args.output_dir, verbose=args.verbose, dpi=args.dpi)
    plot.plt.close(fig)
