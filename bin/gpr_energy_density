#!/usr/bin/env python

__usage__ = "gpr_energy_density [--options] eos.csv [eos.csv eos.csv ...]"
__doc__ = "a one-stop shop for the full GPR regression for energy_density/c2 as a function of pressurec2. The regression is done directly for loge(logp)."
__author__ = "reed.essick@ligo.org"

#-------------------------------------------------

import os
import pickle ### FIXME: figure out a better way to represent the process on disk than this...

import numpy as np

import matplotlib
matplotlib.use("Agg")
from matplotlib import pyplot as plt

from optparse import OptionParser

### non-standard
from universality import utils
from universality import gaussianprocess as gp

#-------------------------------------------------

__default_min_pressure__ = 1e30 ### g/cm^3
__default_max_pressure__ = 1e38

__default_num__ = 51

__default_poly_degree__ = 1

__default_model_multiplier__ = 1

#-------------------------------------------------

def sanity_check_plot(x_tst, f_tst, std_tst, x_obs, f_obs):
    '''
    a helper function for plotting regressions as a way to sanity check results
    '''
    xmin = np.min(x_tst)
    xmax = np.max(x_tst)

    fig = plt.figure()
    foo = fig.add_axes([0.13, 0.30, 0.85, 0.65]) ### the actual data
    res = fig.add_axes([0.13, 0.10, 0.85, 0.19]) ### residuals between data

    ### plot the regression
    foo.fill_between(x_tst, f_tst-std_tst, f_tst+std_tst, color='grey', alpha=0.5)
    foo.plot(x_tst, f_tst, color='k')

    ylim = foo.get_ylim()

    res.fill_between(x_tst, -std_tst/f_tst, +std_tst/f_tst, color='grey', alpha=0.5)
    res.plot(x_tst, np.zeros_like(x_tst, dtype='int'), color='k')

    ### iterate through observed data and overlay
    for x, f in zip(x_obs, f_obs):
        color = foo.plot(x, f, '.-', alpha=0.5)[0].get_color()
        truth = (xmin<=x)*(x<=xmax)
        x = x[truth]
        f = f[truth]
        f_int = np.interp(x, x_tst, f_tst)
        res.plot(x, (f_int-f)/f_int, '.-', color=color, alpha=0.5) ### plot the residual at the observed points

    ### decorate
    plt.setp(foo.get_xticklabels(), visible=False)

    for ax in [foo, res]:
      ax.set_xlim(xmin=xmin, xmax=xmax)
      ax.grid(True, which='both')

    foo.set_ylim(ylim)

    res.set_xlabel('$x$')
    res.set_ylabel(r'$(f_\ast-f)/f_\ast$')
    foo.set_ylabel('$f$')

    return fig, (foo, res)

#-------------------------------------------------

parser = OptionParser(usage=__usage__, description=__doc__)

parser.add_option('-v', '--verbose', default=False, action='store_true')

#--- options for resampling
parser.add_option('', '--resample-pressure-bounds', default=(__default_min_pressure__, __default_max_pressure__), nargs=2, type='float',
    help='min max values for resample-pressure. Specified in g/cm^3. \
DEFAULT=%.3e %.3e'%(__default_min_pressure__, __default_max_pressure__))
parser.add_option('', '--resample-pressure-num', default=51, type='int',
    help='resample to this number of points. \
DEFAULT=%d'%__default_num__)

parser.add_option('', '--resample-poly-degree', default=__default_poly_degree__, type='int',
    help='the degree of the polynomial used to model eos before GPR as part of resampling. \
DEFAULT=%d'%__default_poly_degree__)

parser.add_option('', '--resample-sigma', default=gp.__default_sigma__, type='float',
    help='used as a guess for the optimizer. \
DEFAULT=%.3e'%gp.__default_sigma__)
parser.add_option('', '--resample-l', default=gp.__default_l__, type='float',
    help='used as a guess for the optimizer. \
DEFAULT=%.3e'%gp.__default_l__)
parser.add_option('', '--resample-sigma_obs', default=gp.__default_sigma__, type='float',
    help='used as a guess for the optimizer. \
DEFAULT=%.3e'%gp.__default_sigma__)

#--- options for evaluation
parser.add_option('', '--evaluate-pressure-bounds', default=(__default_min_pressure__, __default_max_pressure__), nargs=2, type='float',
    help='min max values for evaluation pressures. Specified in g/cm^3. \
DEFAULT=%.3e %.3e'%(__default_min_pressure__, __default_max_pressure__))
parser.add_option('', '--evaluate-pressure-num', default=__default_num__, type='int',
    help='evaluate at this number of points. \
DEFAULT=%d'%__default_num__)

parser.add_option('', '--evaluate-poly-degree', default=__default_poly_degree__, type='int',
    help='the degree of the polynomial used to model eos before GPR as part of evaluation. \
DEFAULT=%d'%__default_poly_degree__)

parser.add_option('', '--evaluate-sigma', default=gp.__default_sigma__, type='float',
    help='used as a guess for the optimizer. \
DEFAULT=%.3e'%gp.__default_sigma__)
parser.add_option('', '--evaluate-l', default=gp.__default_l__, type='float',
    help='used as a guess for the optimizer. \
DEFAULT=%.3e'%gp.__default_l__)
parser.add_option('', '--evaluate-sigma_obs', default=gp.__default_sigma__, type='float',
    help='used as a guess for the optimizer. \
DEFAULT=%.3e'%gp.__default_sigma__)

parser.add_option('', '--evaluate-model_multiplier', default=__default_model_multiplier__, type='float',
    help='multiplicative factor for theoretical variance. Larger values increase the "theory noise" from the variance between resampled curves. \
Note, this is applied to the variance, not the standard deviation. \
Default=%d'%__default_model_multiplier__)

#--- output options
parser.add_option('', '--resample-plot', default=False, action='store_true',
    help='generate plots for each resampled eos for sanity checking purposes')
parser.add_option('', '--evaluate-plot', default=False, action='store_true',
    help='generate plots for altogether regression for sanity checking purposes')

parser.add_option('-o', '--output-dir', default='.', type='string')
parser.add_option('-t', '--tag', default='', type='string')

opts, args = parser.parse_args()
Neos = len(args)
assert Neos, 'please supply at least 1 input argument\n%s'%__usage__

if not os.path.exists(opts.output_dir):
    os.makedirs(opts.output_dir)

if opts.tag:
    opts.tag = "_"+opts.tag

#-------------------------------------------------

### resample eos into a big matrix
### generate all data structures we'll need here
if opts.verbose:
    print('resampling to %d points within [%.3e, %.3e] g/cm^3'%((opts.resample_pressure_num,)+opts.resample_pressure_bounds))
logp_resample = np.linspace(
    np.log(opts.resample_pressure_bounds[0]),
    np.log(opts.resample_pressure_bounds[1]),
    opts.resample_pressure_num,
)
logp_resample -= 2*np.log(utils.c)

### set up data structures for "altogether" regression
#Nobs = Neos*opts.resample_pressure_num ### the total number of observation points we'll end up with after resampling
#means = np.empty(Nobs, dtype='float') ### don't zero this because we overwrite every element
#covs = np.zeros((Nobs, Nobs), dtype='float') ### do zero this because we add to this instead of assigning values
means = []
covs = []
logps = []
truths = []

for ind, path in enumerate(args): ### iterate over supplied EOS, resample, and fill in data structures
    if opts.verbose:
        print('reading: '+path)
    data, _ = utils.load(path, ['pressurec2', 'energy_densityc2'])
    logp_obs = np.log(data[:,0])
    loge_obs = np.log(data[:,1])

    ### run gpr to resample this eos
    if opts.verbose:
        print('resampling %d observations to %d points'%(len(loge_obs), opts.resample_pressure_num))
    truth = (np.min(logp_obs)<=logp_resample)*(logp_resample<=np.max(logp_obs)) ### only keep samples below the max tabulated value
    if not np.any(truth):
        raise Warning, 'no samples found with requested range. Skipping this EOS'
        continue
            
    mean, cov = gp.gpr_resample(
        logp_resample[truth],
        loge_obs,
        logp_obs,
        degree=opts.resample_poly_degree,
        guess_sigma2=opts.resample_sigma**2,
        guess_l2=opts.resample_l**2,
        guess_sigma2_obs=opts.resample_sigma_obs**2,
    )

    ### store these for when we build the big covariance matrix for the "altogether" regression
    means.append(mean)
    covs.append(cov)
    logps.append(logp_resample[truth])
    truths.append(truth)

    ### save the process for this resample to file
    pklpath = os.path.join(opts.output_dir, 'gpr_energy_density-%s%s.pkl'%(os.path.basename(path)[:-4], opts.tag))
    if opts.verbose:
        print('writing process to: '+pklpath)
    with open(pklpath, 'w') as file_obj:
        pickle.dump(logp_resample[truth], file_obj)
        pickle.dump(mean, file_obj)
        pickle.dump(cov, file_obj)

    ### plot the result
    if opts.resample_plot:
        figname = pklpath[:-3]+'png'
        if opts.verbose:
            print('saving: '+figname)
        fig = sanity_check_plot(logp_resample[truth], mean, np.diag(cov)**0.5, [logp_obs], [loge_obs])[0]
        fig.suptitle(os.path.basename(path)[:-4])
        fig.savefig(figname)
        plt.close(fig)

if opts.verbose:
    print('computing modeling uncertainty at each pressure')
### reference arrays concerning the lengths of each sample
lens = [len(_) for _ in means]
clens = np.cumsum(lens)
slens = [0]+[_ for _ in clens[:-1]]

### reshape resampled vectors into 1D arrays
means_1d = np.concatenate(means)
logps_1d = np.concatenate(logps)
Nobs = len(logps_1d)

### add in "theory model noise" as diagonal components based on variance of means at each pressure
covs_2d = np.zeros((Nobs,Nobs), dtype='float')

### iterate through pressure samples and compute theory variance of each
for i in xrange(opts.resample_pressure_num):
    ### variance for this pressure sample
    sample_means = []
    sample_vars = []
    for mean, cov, truth in zip(means, covs, truths):
        if truth[i]:
            ind = np.sum(truth[:i+1])-1
            sample_means.append( mean[ind] )
            sample_vars.append( cov[ind,ind] )
    var = np.var(sample_means) + np.sum(sample_vars) if sample_means else 0. ### only take the variance if there's a non-trivial sample at this pressure

    # multiply this sample by some factor (hyper-parameter)
    var *= opts.evaluate_model_multiplier

    # fill in big array as needed
    for j in xrange(Neos):
        if i<lens[j]: # if this EOS goes to high enough pressure, add in this variance
            ind = slens[j]+i
            covs_2d[ind,ind] += var ### variance goes on the diagonal

### iterate over regression covariances and fill in the matrix
### this includes off-diagonal correlations within each resampling
i=0
for ind in xrange(Neos):
    j = clens[ind]
    covs_2d[i:j,i:j] += covs[ind]
    i = j

#------------------------

### perform the "altogether" regression
if opts.verbose:
    print('evaluating log(e) at %d points within [%.3e, %.3e] g/cm^3'%((opts.evaluate_pressure_num,)+opts.evaluate_pressure_bounds))
logp_evaluate = np.linspace(
    np.log(opts.evaluate_pressure_bounds[0]),
    np.log(opts.evaluate_pressure_bounds[1]),
    opts.evaluate_pressure_num,
)
logp_evaluate -= 2*np.log(utils.c)

if opts.verbose:
    print('regressing %d values from %d noisy observations'%(opts.evaluate_pressure_num, Nobs))
mean, cov = gp.gpr_altogether(
    logp_evaluate,
    means_1d,
    logps_1d,
    covs_2d,
    degree=opts.evaluate_poly_degree,
    guess_sigma2=opts.evaluate_sigma**2,
    guess_l2=opts.evaluate_l**2,
    guess_sigma2_obs=opts.evaluate_sigma_obs**2,
)

### save the result
pklpath = os.path.join(opts.output_dir, 'gpr_energy_density%s.pkl'%opts.tag)
if opts.verbose:
    print('writing process to: '+pklpath)
with open(pklpath, 'w') as file_obj:
    pickle.dump(logp_evaluate, file_obj)
    pickle.dump(mean, file_obj)
    pickle.dump(cov, file_obj)

### plot the result
if opts.evaluate_plot:
    figname = pklpath[:-3]+'png'
    if opts.verbose:
        print('saving: '+figname)
    fig = sanity_check_plot(logp_evaluate, mean, np.diag(cov)**0.5, logps, means)[0]
    fig.savefig(figname)
    plt.close(fig)
