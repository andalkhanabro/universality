#!/usr/bin/env python

__usage__ = "gpr_phi [--options] eos.csv [eos.csv eos.csv ...]"
__doc__ = "a one-stop shop for the full GPR regression for phi = log(denergy_density/dpressure -1) as a function of pressurec2."
__author__ = "reed.essick@ligo.org"

#-------------------------------------------------

import os

import numpy as np

import matplotlib
matplotlib.use("Agg")
from matplotlib import pyplot as plt

from optparse import OptionParser

### non-standard
from universality import utils
from universality import gaussianprocess as gp

#-------------------------------------------------

__default_min_pressure__ = 1e30 ### g/cm^3
__default_max_pressure__ = 1e38

__default_num__ = 51

__default_poly_degree__ = 1

__default_model_multiplier__ = 1

#-------------------------------------------------

def big_sanity_check_plot(x_tst, f_tst, dfdx_tst, phi_tst, std_f, std_dfdx, std_phi, x_obs, f_obs):
    '''
    a basic set of plots for sanity-checking the regression
    '''
    xmin = np.min(x_tst)
    xmax = np.max(x_tst)

    zeros = np.zeros_like(x_tst, dtype='int')

    ### compute dfdx_obs and phi_obs
    dfdx_obs = []
    phi_obs = []
    for x, f in zip(x_obs, f_obs):

        # numerically estimate df/dx
        dfdx = gp.num_dfdx(x, f)
        dfdx_obs.append(dfdx) # add to list

        # compute phi = np.log(np.exp(f)/np.exp(x) * dfdx - 1)
        phi_obs.append( np.log(np.exp(f)/np.exp(x)*dfdx - 1) )

    ### set up figures and axes
    fig = plt.figure(figsize=(18,6))

    foo = plt.subplot(2,3,1) # the function itself
    res = plt.subplot(2,3,4) # the residual between GPR and the function

    doo = plt.subplot(2,3,2) # derivative of the function
    des = plt.subplot(2,3,5) # residual in derivative of the function

    phi = plt.subplot(2,3,3) # phi = log(df/dx - 1)
    pes = plt.subplot(2,3,6) # residuals of phi

    plt.subplots_adjust(
        hspace=0.02,
        wspace=0.2,
        left=0.08,
        right=0.99,
        bottom=0.10,
        top=0.90,
    )

    ### plot the regression
    std_f *= 3 ### plot 3-sigma region
    foo.fill_between(x_tst, f_tst-std_f, f_tst+std_f, color='grey', alpha=0.5)
    foo.plot(x_tst, f_tst, color='k')

#    res.fill_between(x_tst, -std_f/f_tst, +std_f/f_tst, color='grey', alpha=0.5)
    res.fill_between(x_tst, -std_f, +std_f, color='grey', alpha=0.5)
    res.plot(x_tst, zeros, color='k')

    ylim = foo.get_ylim(), 2*np.array(res.get_ylim())

    # iterate and overlay data
    for x, f in zip(x_obs, f_obs):
        color = foo.plot(x, f, '.-', alpha=0.5)[0].get_color()
        truth = (xmin<=x)*(x<=xmax)
        x = x[truth]
        f = f[truth]
        f_int = np.interp(x, x_tst, f_tst)
#        res.plot(x, (f_int-f)/f_int, '.-', color=color, alpha=0.5) ### plot the residual at the observed points
        res.plot(x, f_int-f, '.-', color=color, alpha=0.5) ### plot the residual at the observed points

    foo.set_ylim(ylim[0])
    res.set_ylim(ylim[1])

    # decorate regression
    plt.setp(foo.get_xticklabels(), visible=False)

    for ax in [foo, res]:
      ax.set_xlim(xmin=xmin, xmax=xmax)
      ax.grid(True, which='both')

    res.set_xlabel('$x$')
#    res.set_ylabel(r'$(f_\ast-f)/f_\ast$')
    res.set_ylabel(r'$f_\ast-f$')
    foo.set_ylabel('$f$')
    
    ### plot the regression of dfdx
    std_dfdx *= 3 ### plot 3-sigma region
    doo.fill_between(x_tst, dfdx_tst+std_dfdx, dfdx_tst-std_dfdx, color='grey', alpha=0.5)
    doo.plot(x_tst, dfdx_tst, color='k')

#    des.fill_between(x_tst, -std_dfdx/dfdx_tst, +std_dfdx/dfdx_tst, color='grey', alpha=0.5)
    des.fill_between(x_tst, -std_dfdx, +std_dfdx, color='grey', alpha=0.5)
    des.plot(x_tst, zeros, color='k')

    ylim = doo.get_ylim(), 2*np.array(des.get_ylim())

    # iterate and overlay data
    for x, dfdx in zip(x_obs, dfdx_obs):
        color = doo.plot(x, dfdx, '.-', alpha=0.5)[0].get_color()
        truth = (xmin<=x)*(x<=xmax)
        x = x[truth]
        dfdx = dfdx[truth]
        f_int = np.interp(x, x_tst, dfdx_tst)
#        des.plot(x, (f_int-dfdx)/f_int, '.-', color=color, alpha=0.5) ### plot the residual at the observed points
        des.plot(x, f_int-dfdx, '.-', color=color, alpha=0.5) ### plot the residual at the observed points

    doo.set_ylim(ylim[0])
    des.set_ylim(ylim[1])

    # decorate regression of dfdx
    plt.setp(doo.get_xticklabels(), visible=False)

    for ax in [doo, des]:
        ax.set_xlim(xmin=xmin, xmax=xmax)
        ax.grid(True, which='both')

    des.set_xlabel('$x$')
#    des.set_ylabel(r'$([df/dx]_\ast - [df/dx])/[df/dx]_\ast$')
    des.set_ylabel(r'$[df/dx]_\ast - [df/dx]$')
    doo.set_ylabel('df/dx')

    ### plot the regression for phi
    std_phi *= 3 ### plot 3-sigma region
    phi.fill_between(x_tst, mean_phi+std_phi, mean_phi-std_phi, color='grey', alpha=0.5)
    phi.plot(x_tst, mean_phi, color='k')

#    pes.fill_between(x_tst, +std_phi/mean_phi, -std_phi/mean_phi, color='grey', alpha=0.5)
    pes.fill_between(x_tst, +std_phi, -std_phi, color='grey', alpha=0.5)
    pes.plot(x_tst, zeros, color='k')

    ylim = phi.get_ylim(), 2*np.array(pes.get_ylim())

    # iterate over data
    for x, p in zip(x_obs, phi_obs):
        color = phi.plot(x, p, '.-', alpha=0.5)[0].get_color()
        truth = (xmin<=x)*(x<=xmax)
        x = x[truth]
        p = p[truth]
        f_int = np.interp(x, x_tst, phi_tst)
#        pes.plot(x, (f_int-p)/f_int, '.-', color=color, alpha=0.5) ### plot the residual at the observed points
        pes.plot(x, (f_int-p), '.-', color=color, alpha=0.5) ### plot the residual at the observed points

    phi.set_ylim(ylim[0])
    pes.set_ylim(ylim[1])

    # decorate regression of phi
    plt.setp(phi.get_xticklabels(), visible=False)

    for ax in [phi, pes]:
        ax.set_xlim(xmin=xmin, xmax=xmax)
        ax.grid(True, which='both')

    pes.set_xlabel('$x$')
#    pes.set_ylabel(r'$(\phi_\ast - \phi)/\phi_\ast$')
    pes.set_ylabel(r'$(\phi_\ast - \phi)$')
    phi.set_ylabel('$\phi$')

    ### return
    return fig, (foo, res), (doo, des), (phi, pes)

def sanity_check_plot(x_tst, f_tst, std_tst, x_obs, f_obs, std_obs):
    '''
    a helper function for plotting regressions as a way to sanity check results
    '''
    xmin = np.min(x_tst)
    xmax = np.max(x_tst)

    fig = plt.figure()
    foo = fig.add_axes([0.13, 0.30, 0.85, 0.65]) ### the actual data
    res = fig.add_axes([0.13, 0.10, 0.85, 0.19]) ### residuals between data

    ### plot the regression
    std_tst *= 3 ### plot 3-sigma region
    foo.fill_between(x_tst, f_tst-std_tst, f_tst+std_tst, color='grey', alpha=0.5)
    foo.plot(x_tst, f_tst, color='k')

    ylim = foo.get_ylim()

    res.fill_between(x_tst, -std_tst, +std_tst, color='grey', alpha=0.5)
    res.plot(x_tst, np.zeros_like(x_tst, dtype='int'), color='k')

    ### iterate through observed data and overlay
    for x, f, s in zip(x_obs, f_obs, std_obs):
        color = foo.plot(x, f, '.-', alpha=0.5)[0].get_color()

        s *= 3 ### plot 3-sigma region
        foo.fill_between(x, f+s, f-s, alpha=0.1, color=color)

        truth = (xmin<=x)*(x<=xmax)
        x = x[truth]
        f = f[truth]
        s = s[truth]
        f_int = np.interp(x, x_tst, f_tst)
        res.plot(x, f_int-f, '.-', color=color, alpha=0.5) ### plot the residual at the observed points
        res.fill_between(x, f_int-f-s, f_int-f+s, alpha=0.1, color=color)

    foo.set_ylim(ylim)

    ### decorate
    plt.setp(foo.get_xticklabels(), visible=False)

    for ax in [foo, res]:
      ax.set_xlim(xmin=xmin, xmax=xmax)
      ax.grid(True, which='both')

    res.set_xlabel('$x$')
    res.set_ylabel(r'$f_\ast-f$')
    foo.set_ylabel('$f$')

    return fig, foo, res

#-------------------------------------------------

parser = OptionParser(usage=__usage__, description=__doc__)

parser.add_option('-v', '--verbose', default=False, action='store_true')

#--- options for resampling
parser.add_option('', '--resample-pressure-bounds', default=(__default_min_pressure__, __default_max_pressure__), nargs=2, type='float',
    help='min max values for resample-pressure. Specified in g/cm^3. \
DEFAULT=%.3e %.3e'%(__default_min_pressure__, __default_max_pressure__))
parser.add_option('', '--resample-pressure-num', default=51, type='int',
    help='resample to this number of points. \
DEFAULT=%d'%__default_num__)

parser.add_option('', '--resample-poly-degree', default=__default_poly_degree__, type='int',
    help='the degree of the polynomial used to model eos before GPR as part of resampling. \
DEFAULT=%d'%__default_poly_degree__)

parser.add_option('', '--resample-sigma', default=gp.__default_sigma__, type='float',
    help='used as a guess for the optimizer. \
DEFAULT=%.3e'%gp.__default_sigma__)
parser.add_option('', '--resample-l', default=gp.__default_l__, type='float',
    help='used as a guess for the optimizer. \
DEFAULT=%.3e'%gp.__default_l__)
parser.add_option('', '--resample-sigma_obs', default=gp.__default_sigma__, type='float',
    help='used as a guess for the optimizer. \
DEFAULT=%.3e'%gp.__default_sigma__)

parser.add_option('', '--check-for-nan', default=False, action='store_true',
    help='look for nans during resampling step. If they are found, raise a ValueError')

#--- options for evaluation
parser.add_option('', '--evaluate-pressure-bounds', default=(__default_min_pressure__, __default_max_pressure__), nargs=2, type='float',
    help='min max values for evaluation pressures. Specified in g/cm^3. \
DEFAULT=%.3e %.3e'%(__default_min_pressure__, __default_max_pressure__))
parser.add_option('', '--evaluate-pressure-num', default=__default_num__, type='int',
    help='evaluate at this number of points. \
DEFAULT=%d'%__default_num__)

parser.add_option('', '--evaluate-poly-degree', default=__default_poly_degree__, type='int',
    help='the degree of the polynomial used to model eos before GPR as part of evaluation. \
DEFAULT=%d'%__default_poly_degree__)

parser.add_option('', '--evaluate-sigma', default=gp.__default_sigma__, type='float',
    help='used as a guess for the optimizer. \
DEFAULT=%.3e'%gp.__default_sigma__)
parser.add_option('', '--evaluate-l', default=gp.__default_l__, type='float',
    help='used as a guess for the optimizer. \
DEFAULT=%.3e'%gp.__default_l__)
parser.add_option('', '--evaluate-sigma_obs', default=gp.__default_sigma__, type='float',
    help='used as a guess for the optimizer. \
DEFAULT=%.3e'%gp.__default_sigma__)

parser.add_option('', '--evaluate-model_multiplier', default=__default_model_multiplier__, type='float',
    help='multiplicative factor for theoretical variance. Larger values increase the "theory noise" from the variance between resampled curves. \
Default=%d'%__default_model_multiplier__)

#--- output options
parser.add_option('', '--resample-plot', default=False, action='store_true',
    help='generate plots for each resampled eos for sanity checking purposes')
parser.add_option('', '--evaluate-plot', default=False, action='store_true',
    help='generate plots for altogether regression for sanity checking purposes')

parser.add_option('-o', '--output-dir', default='.', type='string')
parser.add_option('-t', '--tag', default='', type='string')

opts, args = parser.parse_args()
Neos = len(args)
assert Neos, 'please supply at least 1 input argument\n%s'%__usage__

if not os.path.exists(opts.output_dir):
    os.makedirs(opts.output_dir)

if opts.tag:
    opts.tag = "_"+opts.tag

#-------------------------------------------------

### resample eos into a big matrix
### generate all data structures we'll need here
if opts.verbose:
    print('resampling to %d points within [%.3e, %.3e] g/cm^3'%((opts.resample_pressure_num,)+opts.resample_pressure_bounds))
logp_resample = np.linspace(
    np.log(opts.resample_pressure_bounds[0]),
    np.log(opts.resample_pressure_bounds[1]),
    opts.resample_pressure_num,
)
logp_resample -= 2*np.log(utils.c)

### set up data structures for "altogether" regression
#Nobs = Neos*opts.resample_pressure_num ### the total number of observation points we'll end up with after resampling
#means = np.empty(Nobs, dtype='float') ### don't zero this because we overwrite every element
#covs = np.zeros((Nobs, Nobs), dtype='float') ### do zero this because we add to this instead of assigning values
means = []
covs = []

logps = []
truths = []

for ind, path in enumerate(args): ### iterate over supplied EOS, resample, and fill in data structures
    if opts.verbose:
        print('reading: '+path)
    data, _ = utils.load(path, ['pressurec2', 'energy_densityc2'])
    logp_obs = np.log(data[:,0])
    loge_obs = np.log(data[:,1])

    ### run gpr to resample this eos
    if opts.verbose:
        print('resampling %d observations to %d+%d points'%(len(loge_obs), opts.resample_pressure_num, opts.resample_pressure_num))
    truth = (np.min(logp_obs)<=logp_resample)*(logp_resample<=np.max(logp_obs)) ### only keep samples below the max tabulated value
    if not np.any(truth):
        raise Warning, 'no samples found with requested range. Skipping this EOS'
        continue

    mean_f, mean_dfdx, cov_f_f, cov_f_dfdx, cov_dfdx_f, cov_dfdx_dfdx = gp.gpr_resample_f_dfdx(
        logp_resample[truth],
        loge_obs,
        logp_obs,
        degree=opts.resample_poly_degree,
        guess_sigma2=opts.resample_sigma**2,
        guess_l2=opts.resample_l**2,
        guess_sigma2_obs=opts.resample_sigma_obs**2,
    )

    if opts.verbose:
        print('computing process for phi')
    mean_phi, truth_phi = gp.mean_phi(logp_resample[truth], mean_f, mean_dfdx)
    mean_phi = mean_phi[truth_phi] ### prune bad (acausal?) samples from the data set!
    TRUTH = truth[:]
    TRUTH[truth] = truth_phi

    cov_phi_phi = gp.cov_phi_phi(
        logp_resample[TRUTH],
        mean_f[truth_phi],
        mean_dfdx[truth_phi],
        cov_f_f[truth_phi,:][:,truth_phi],
        cov_f_dfdx[truth_phi,:][:,truth_phi],
        cov_dfdx_f[truth_phi,:][:,truth_phi],
        cov_dfdx_dfdx[truth_phi,:][:,truth_phi],
    )

    ### store these for when we build the big covariance matrix for the "altogether" regression
    means.append(mean_phi)
    covs.append(cov_phi_phi)
    logps.append(logp_resample[truth])
    truths.append(truth)

    ### save the process for this resample to file
    ### NOTE: we do not actually record the full covariance matrix between f and df/dx. That's probably not needed, so this is probably ok

    # just f
    pklpath = os.path.join(opts.output_dir, 'gpr_phi-f-%s%s.pkl'%(os.path.basename(path)[:-4], opts.tag))
    if opts.verbose:
        print('writing process to: '+pklpath)
    gp.pkldump(pklpath, 'logpressurec2', 'logenergy_densityc2', logp_resample[truth], mean_f, cov_f_f)

    # just df/dx
    pklpath = os.path.join(opts.output_dir, 'gpr_phi-dfdx-%s%s.pkl'%(os.path.basename(path)[:-4], opts.tag))
    if opts.verbose:
        print('writing process to: '+pklpath)
    gp.pkldump(pklpath, 'logpressurec2', 'dlogenergy_densitydpressure', logp_resample[truth], mean_dfdx, cov_dfdx_dfdx)
    
    # just phi
    pklpath = os.path.join(opts.output_dir, 'gpr_phi-%s%s.pkl'%(os.path.basename(path)[:-4], opts.tag))
    if opts.verbose:
        print('writing process to: '+pklpath)
    gp.pkldump(pklpath, 'logpressurec2', 'phi', logp_resample[TRUTH], mean_phi, cov_phi_phi)

    ### plot the result
    if opts.resample_plot:
        figname = pklpath[:-3]+'png'
        if opts.verbose:
            print('saving: '+figname)
        fig = big_sanity_check_plot(
            logp_resample[TRUTH],
            mean_f[truth_phi],
            mean_dfdx[truth_phi],
            mean_phi,
            (np.diag(cov_f_f)**0.5)[truth_phi],
            (np.diag(cov_dfdx_dfdx)**0.5)[truth_phi],
            np.diag(cov_phi_phi)**0.5,
            [logp_obs],
            [loge_obs],
        )[0]
        fig.suptitle(os.path.basename(path)[:-4])
        fig.savefig(figname)
        plt.close(fig)

    ### run basic sanity checks to make sure we don't break anything downstream...
    if opts.check_for_nan:
        if np.any(mean_phi!=mean_phi):
            raise ValueError, path+' produces nans for mean_phi when resampled!'
        if np.any(cov_phi_phi!=cov_phi_phi):
            raise ValueError, path+' producds nans for cov_phi_phi when resampled!'

#-------------------------------------------------
# below this point, I only care about phi and therefore neglect f, dfdx, etc
#-------------------------------------------------

if opts.verbose:
    print('computing modeling uncertainty at each pressure')
### reference arrays concerning the lengths of each sample
lens = [len(_) for _ in means]
clens = np.cumsum(lens)
slens = [0]+[_ for _ in clens[:-1]]

### reshape resampled vectors into 1D arrays
means_1d = np.concatenate(means)
logps_1d = np.concatenate(logps)
Nobs = len(logps_1d)

### add in "theory model noise" as diagonal components based on variance of means at each pressure
covs_2d = np.zeros((Nobs,Nobs), dtype='float')

### iterate through pressure samples and compute theory variance of each
for i in xrange(opts.resample_pressure_num):
    ### variance for this pressure sample
    sample_means = []
    sample_vars = []
    for mean, cov, truth in zip(means, covs, truths):
        if truth[i]:
            ind = np.sum(truth[:i+1])-1
            sample_means.append( mean[ind] )
            sample_vars.append( cov[ind,ind] )
    var = np.var(sample_means) + np.sum(sample_vars) if sample_means else 0. ### only take the variance if there's a non-trivial sample at this pressure

    # multiply this sample by some factor (hyper-parameter)
    var *= opts.evaluate_model_multiplier

    # fill in big array as needed
    for j in xrange(Neos):
        if i<lens[j]: # if this EOS goes to high enough pressure, add in this variance
            ind = slens[j]+i
            covs_2d[ind,ind] += var ### variance goes on the diagonal

### iterate over regression covariances and fill in the matrix
### this includes off-diagonal correlations within each resampling
i=0
for ind in xrange(Neos):
    j = clens[ind]
    covs_2d[i:j,i:j] += covs[ind]
    i = j

#------------------------

### perform the "altogether" regression
if opts.verbose:
    print('evaluating log(e) at %d points within [%.3e, %.3e] g/cm^3'%((opts.evaluate_pressure_num,)+opts.evaluate_pressure_bounds))
logp_evaluate = np.linspace(
    np.log(opts.evaluate_pressure_bounds[0]),
    np.log(opts.evaluate_pressure_bounds[1]),
    opts.evaluate_pressure_num,
)
logp_evaluate -= 2*np.log(utils.c)

if opts.verbose:
    print('regressing %d values from %d noisy observations'%(opts.evaluate_pressure_num, Nobs))
mean, cov = gp.gpr_altogether(
    logp_evaluate,
    means_1d,
    logps_1d,
    covs_2d,
    degree=opts.evaluate_poly_degree,
    guess_sigma2=opts.evaluate_sigma**2,
    guess_l2=opts.evaluate_l**2,
    guess_sigma2_obs=opts.evaluate_sigma_obs**2,
)

### save the result
pklpath = os.path.join(opts.output_dir, 'gpr_phi%s.pkl'%opts.tag)
if opts.verbose:
    print('writing process to: '+pklpath)
gp.pkldump(pklpath, 'logpressurec2', 'phi', logp_evaluate, mean, cov)

### plot the result
if opts.evaluate_plot:
    figname = pklpath[:-3]+'png'
    if opts.verbose:
        print('saving: '+figname)
    fig, _, _ = sanity_check_plot(
        logp_evaluate,
        mean,
        np.diag(cov)**0.5,
        logps,
        means,
        [np.diag(c)**0.5 for c in covs],
    )
    fig.savefig(figname)
    plt.close(fig)
