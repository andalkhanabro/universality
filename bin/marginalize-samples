#!/usr/bin/env python

"""marginalize over all weights associated with combinations of columns, creating a new file with marginalized weights within it
"""
__author__ = "Reed Essick (reed.essick@gmail.com)"

#-------------------------------------------------

import os
import numpy as np

from collections import defaultdict
from argparse import ArgumentParser

### non-standard libraries
from universality import utils

#-------------------------------------------------

parser = ArgumentParser(description=__doc__)

parser.add_argument('samples', type=str)
parser.add_argument('columns', nargs="+", type=str,
    help='columns used to define unique sets. We will marginalize over anything not specified here')

parser.add_argument('--weight-column', default=[], type=str, action='append')
parser.add_argument('--weight-column-is-log', default=[], type=str, action='append')
parser.add_argument('--max-num-samples', default=utils.DEFAULT_MAX_NUM_SAMPLES, type=int)

parser.add_argument('-v', '--verbose', default=False, action='store_true')
parser.add_argument('-o', '--output-path', default=None, type=str,
    help='default behavior is to overwrite the input samples, but we require confirmation from the user before the script will do this.')

args = parser.parse_args()

if args.output_path is None:
    if raw_input('WARNING: you are about to overwrite your input file (%s).\nAre you sure you want to do this? [Y/n]'%args.samples) != 'Y':
        import sys
        sys.exit(1)
    args.output_path = args.samples

#-------------------------------------------------

if args.verbose:
    print('reading samples from: '+args.samples)
data, columns = utils.load(args.samples, args.columns, max_num_samples=args.max_num_samples)

if args.weight_column:
    if args.verbose:
        print('reading in non-trivial weights from: '+args.samples)
    logweights = utils.load_logweights(
        args.samples,
        args.weight_column,
        logweightcolumns=args.weight_column_is_log,
        max_num_samples=args.max_num_samples,
    )

else:
    N = len(data)
    logweights = -np.ones(N, dtype='float')*np.log(N)

# now need to marginalize over samples
if args.verbose:
    print('marginalizing over weights to determine effective weights for unique combinations of (%s)'%(', '.join(args.columns)))

logmargweight = defaultdict(float)
counts = defaultdict(int)
for sample, logweight in zip(data, logweights):
    tup = tuple(sample)
    logmargweight[tup] = utils.sum_log((logmargweight[tup], logweight))
    counts[tup] += 1 

num_columns = len(columns)
columns = columns+['logmargweight', 'num_elements'] ### store the columns requested, the marginalized weight, and the number of elements included in the set for this particular tuple

# format the array as needed
if args.verbose:
    print('reformatting data into an array...')
results = np.empty((len(logmargweight.keys()), len(columns)), dtype=float)
for i, key in enumerate(logmargweight.keys()):
    results[i,:num_columns] = key
    results[i,num_columns:] = logmargweight[key], counts[key]

# write output CSV file
if args.verbose:
    print('writing marginalized results to: '+args.output_path)

outdir = os.path.dirname(args.output_path)
if not os.path.exists(outdir):
    os.makedirs(outdir)

np.savetxt(args.output_path, results, header=','.join(columns), comments='', delimiter=',')
