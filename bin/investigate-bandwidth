#!/usr/bin/env python

"""finds the optimal bandwidth for a KDE representation of samples in an N-dimensional space
"""
__author__ = "Reed Essick (reed.essick@gmail.com)"

#-------------------------------------------------

import os
import numpy as np

from argparse import ArgumentParser

### non-standard libraries
from universality.utils import (utils, io)
from universality import plot
from universality import kde

#-------------------------------------------------

parser = ArgumentParser(description=__doc__)

parser.add_argument('inpath', type=str)
parser.add_argument('columns', nargs='+', type=str)

parser.add_argument('-v', '--verbose', default=False, action='store_true')
parser.add_argument('-V', '--Verbose', default=False, action='store_true')

parser.add_argument('--logcolumn', default=[], type=str, action='append',
    help='convert the values read in for this column to natural log. \
Can be repeated to specify multiple columns. \
DEFAULT=[]')

parser.add_argument('--num-withheld', default=1, type=int,
    help='the number of samples to withhold in the cross-validation likelihood. \
Larger values should result in faster run-times (fewer sets to evaluate), but may result in worsened logL estimates.')

parser.add_argument('--num-proc', default=utils.DEFAULT_NUM_PROC, type=int,
    help='DEFAULT=%d'%utils.DEFAULT_NUM_PROC)
parser.add_argument('-b', '--bandwidth', default=[], type=float, action='append',
    help='the bandwidth (standard deviation) used within the Gaussian KDE. \
User can investigate multiple bandwidths by repeating this option. \
DEFAULT=[]')

parser.add_argument('--max-num-samples', default=utils.DEFAULT_MAX_NUM_SAMPLES, type=int)

parser.add_argument('--weight-column', default=[], type=str, action='append',
    help='if provided, thie numerical values from this column will be used as weights in the KDE')
parser.add_argument('--weight-column-is-log', default=[], type=str, action='append',
    help='if supplied, interpret the values in weight_column as log(weight), meaning we exponentiate them before using them in the KDE')
parser.add_argument('--invert-weight-column', default=[], type=str, action='append',
    help='After extracting the weights from source_samples.csv, this will compute the KDE using the inverse of those values; e.g.: weight by the inverse of the prior for a set of posterior samples so the effective sampling is with respect to the likelihood. The inversion is done after exponentiation when --weight-column-is-log is supplied.')

parser.add_argument('--num-points', default=101, type=int,
    help='the number of points used on each dimension of the hyper-cube used to estimate the KDE when plotting the results. \
NOTE: computing the KDE on all these grid points will scale poorly with larger --num-pts; user be warned. \
DEFAULT=101')

parser.add_argument('-p', '--plot', default=False, action='store_true')
parser.add_argument('--no-scatter', default=False, action='store_true',
    help='do not plot sample points in the KDE corner plot')
parser.add_argument('-o', '--output-dir', default='.', type=str)
parser.add_argument('-t', '--tag', default='', type=str)

args = parser.parse_args()
Ncol = len(args.columns)

assert len(args.bandwidth), 'please supply at least 1 bandwidth'
args.bandwidth = sorted(args.bandwidth)

if args.tag:
    args.tag = "_"+args.tag

if args.output_dir and (not os.path.exists(args.output_dir)):
    os.makedirs(args.output_dir)

args.verbose |= args.Verbose

#-------------------------------------------------

### read in data from csv
if args.verbose:
    print('reading samples from: '+args.inpath)
data, columns = io.load(args.inpath, args.columns, logcolumns=args.logcolumn, max_num_samples=args.max_num_samples)
Nsamp = len(data)

if args.verbose:
    print('Nsamples = %d'%Nsamp)
    if Ncol > 1:
        print(('Covar\n  '+' '.join(['%-10s']*Ncol))%tuple(columns))
        for row in np.cov(data, rowvar=0):
            print(('  '+' '.join(['%+02.3e']*Ncol)))%tuple(row)
    else:
        print('Covar\n  %-10s'%columns[0])
        print('  %+02.3e'%np.std(data))

# whiten data so a single bandwidth makes more sense
data, means, stds = utils.whiten(data, verbose=args.verbose)

#------------------------

### load in weights
if args.weight_column:
    if args.verbose:
        print('reading in non-trivial weights from: '+args.inpath)
    weights = io.load_weights(
        args.inpath,
        args.weight_column,
        logweightcolumns=args.weight_column_is_log,
        invweightcolumns=args.invert_weight_column,
        max_num_samples=args.max_num_samples,
    )

else:
    weights = np.ones(Nsamp, dtype=float)/Nsamp

#------------------------

### iterate over bandwidths and compute things like log(likelihood) and grad(log(likelihood))
if args.verbose:
    print('analyzing bandwidths')

metrics = dict()
v = np.empty(Ncol, dtype='float')
for b in args.bandwidth:
    if args.verbose:
        print('  b=%.3e'%b)

    v[:] = b**2 ### convert standard deviation into variances. 
                ### Assume diagonal covariance matrix with the same value throughout
    mlogL, vlogL, mdlogLdvp, vdlogLdvp = kde.logleavekoutLikelihood(data, v, k=args.num_withheld, weights=weights, num_proc=args.num_proc)
    metrics[b] = {
        'mean_logL' : mlogL,
        'stdv_logL' : vlogL**0.5,
        'mean_dlogLdlogb' : 2*v[0]*np.sum(mdlogLdvp), ### this makes sense because of our assumption that all variances are the same...
        'stdv_dlogLdlogb' : 2*v[0]*(np.sum(vdlogLdvp))**0.5,  ### this is also correct assuming all variances are the same
    }

    if args.verbose:
        print('''\
    mean_logL = %(mean_logL)+.6e
    stdv_logL = %(stdv_logL)+.6e
    mean_dlogLdlogb = %(mean_dlogLdlogb)+.6e
    stdv_dlogLdlogb = %(stdv_dlogLdlogb)+.6e'''%metrics[b])

    ### FIXME: write these into a CSV for easy of use

#------------------------
### generate plots/visualizations representing results

if args.plot:
    if args.verbose:
        print('plotting')

    #--- likelihood vs bandwidth
    if args.verbose:
        print('bandwidth vs logLikelihood')

    fig = plot.plt.figure()
    ax_logL = plot.plt.subplot(2,1,1)
    ax_glogL = plot.plt.subplot(2,1,2)

    #norm = Nsamp**-0.5 ### normalization for how I expect the std to scale
                       ### we compute it based on single-event validation sets, and we have Nsamp of those
    # plot results for each bandwidth
    for b in args.bandwidth:
       d = metrics[b]
       mlogL = d['mean_logL']
       slogL = d['stdv_logL']#*norm
       mglogL = d['mean_dlogLdlogb']
       sglogL = d['stdv_dlogLdlogb']#*norm
    
       color = ax_logL.semilogx([b]*2, [mlogL-slogL, mlogL+slogL], alpha=0.75)[0].get_color()
       ax_logL.semilogx(b, mlogL, marker='o', color=color)
    
       ax_glogL.semilogx([b]*2, [mglogL-sglogL, mglogL+sglogL], alpha=0.75, color=color)
       ax_glogL.semilogx([b], mglogL, marker='o', color=color)

    # decorate
    xlim = args.bandwidth[0]/1.1, args.bandwidth[-1]*1.1
    for ax in [ax_logL, ax_glogL]:
        ax.set_xlim(xlim)
        ax.grid(True, which='both')

    #ymin, ymax = ax_logL.get_ylim()
    #ax_logL.set_ylim(ymin=ymin-0.5, ymax=ymax+0.5)

    #ymin, ymax = ax_glogL.get_ylim()
    #ax_glogL.set_ylim(ymin=ymin-0.1, ymax=ymax+0.1)

    plot.plt.setp(ax_logL.get_xticklabels(), visible=False)
    ax_glogL.set_xlabel('$b$')

    ax_logL.set_ylabel('$\log L$')
    ax_glogL.set_ylabel(r'$\left.d \log L\right/d \log b$')

    # save
    figname = os.path.join(args.output_dir, 'investigate_bandwidth-logLike%s.png'%args.tag)
    if args.verbose:
        print('saving: '+figname)
    fig.savefig(figname)
    plot.close(fig)

    #--- visualization of resulting KDEs...
    if args.verbose:
        print('visualization of KDE for each bandwidth')

    vects = np.array([np.linspace(np.min(data[:,i]), np.max(data[:,i]), args.num_points) for i in xrange(Ncol)])
    bounds = np.array([np.array([np.min(vect), np.max(vect)]) for vect in vects])

    N = len(data)
    Nbins = max(10, int(N**0.5)/2)
    v = np.empty(Ncol, dtype='float')
    
    shape = (args.num_points, args.num_points) # used to reshape 2D sampling kdes
    
    for b in args.bandwidth:
        v[:] = b
    
        # actually generate figure
        if args.verbose:
            print('  plotting')
        fig = plot.kde_corner(
            data,
            bandwidths=v,
            range=bounds,
            weights=weights,
            hist1D=True,
            scatter=not args.no_scatter,
            verbose=args.Verbose,
        )
    
        # further decorate
        fig.suptitle('$b=%.3e$'%b)
    
        # save
        figname = os.path.join(args.output_dir, 'investigate_bandwidth-kde-%.3e%s.png'%(b, args.tag))
        if args.verbose:
            print('saving: '+figname)
        fig.savefig(figname)
        plot.close(fig)
