#!/usr/bin/env python

"""copy columns from multiple sample CSV into a target CSV
"""
__author__ = "reed.essick@gmail.com"

#-------------------------------------------------

import os
import numpy as np

from argparse import ArgumentParser

### non-standard libraries
from universality import utils

#-------------------------------------------------

parser = ArgumentParser(description=__doc__)

parser.add_argument('reference_columns', nargs='+', type=str,
    help='the column that is used to match rows in samples and target. This must be present in both files. \
It must also have only a single row in source for each value of this column.')
parser.add_argument('output', type=str,
    help='if this file already exists, we require reference_column to exist in that file and then map all the --samples into those rows. \
Otherwise, we create a new file that only containes the columns from the samples')
parser.add_argument('--omit-missing', default=False, action='store_true',
    help='if output already exists, drop any rows that do not have corresponding reference_columns in all of --samples instead of raising an exception.')

parser.add_argument('-s', '--samples', nargs='+', type=str, default=[], action='append',
    help='eg: "--samples path column1 column2 ...". If no columns are supplied, we copy all of them')
parser.add_argument('--column-map', nargs=3, type=str, default=[], action='append',
    help='map the column names from one of --samples into a new name in the output file. Useful if several of the --samples have the same column names. \
eg: "--column-map path old_column new_column"')

parser.add_argument('-v', '--verbose', default=False, action='store_true')
parser.add_argument('-V', '--Verbose', default=False, action='store_true')

args = parser.parse_args()

assert args.samples, 'must supply at least one --samples'

args.verbose |= args.Verbose

samples = dict((samples[0], samples[1:]) for samples in args.samples)

column_maps = dict((source, dict()) for source in samples.keys())
for path, old, new in args.column_map:
    assert path in samples, 'specifying --column-map for unkown sample set: '+path
    column_maps[path][old] = new

Nref = len(args.reference_columns)

#-------------------------------------------------

### read in source data
data = dict()
columns = dict()
refinds = dict()

references = None

for source in samples.keys():

    if args.verbose:
        print('reading data from source: '+source)
    if len(samples[source]):
        d, c = utils.load(source, args.reference_columns+samples[source])
        refind = range(Nref)
    else:
        d, c = utils.load(source)
        for col in args.reference_columns:
            assert col in c, 'reference_column=%s not found in %s'%(col, source)
        refind = [c.index(col) for col in args.reference_columns]

    ref_set = set(tuple(_) for _ in d[:,refind])
    assert len(d)==len(ref_set), 'reference_columns=%s can not have repeated values in different rows'%(','.join(args.reference_columns))

    data[source] = d

    column_map = column_maps[source]
    columns[source] = [column_map.get(col, col) for col in c]

    refinds[source] = refind

    if args.Verbose:
        print('found %d reference values'%len(d))

    if references is None:
        references = ref_set
    else:
        references = references.intersection(ref_set) ### only keep the reference values that are common between all --samples

    if args.Verbose:
        print('retained %d reference values common to all sample sets provided'%len(references))

Ncol = sum(len(c) for c in columns.values()) - len(samples.keys())*len(args.reference_columns) ### the total number of columns that are *not* copies of reference_column

#-------------------------------------------------

### read in target/output
if os.path.exists(args.output):
    if args.verbose:
        print('loading existing columns from: '+args.output)
    d, c = utils.load(args.output)
    for col in args.reference_columns:
        assert col in c, 'reference_column=%s not present in %s'%(col, args.output)
    result_refind = [c.index(col) for col in args.reference_columns]

    ### check to make sure that we have a reference from all --samples for each val present here
    if args.omit_missing:
        truth = np.ones(len(d), dtype=bool)
        for ind, val in enumerate(d[:,result_refind]):
            if tuple(val) not in references: ### there is nothing to map!
                if args.Verbose:
                    print('WARNING! row (%d) found without any corresponding reference value (%f) in all --samples'%(ind, val))
                truth[ind] = False

        if not np.all(truth): ### at least one row needs to be dropped
            if args.verbose:
                print('WARNING! dropped %d / %d rows because their reference value was not present in all --samples'%(np.sum(truth), len(d)))
            d = d[truth]

    else:
        for val in set(tuple(_) for _ in d[:,result_refind]):
            assert val in references, 'there are reference values within %s that do not have corresponding values in all --samples'%args.output

    ### set up holder for final result
    N = len(c)
    result = np.empty((len(d), N+Ncol), dtype=float)
    result[:,:N] = d[...]

    header = c

else:
    ### set up holder for final result
    if args.verbose:
        print('establishing set of unique combinations of reference columns')

    N = Nref
    result_refind = range(Nref)

    result = np.empty((len(references), N+Ncol), dtype=float)
    for ind, val in enumerate(references):
        result[ind,:N] = val

    header = args.reference_columns[:]

#-------------------------------------------------

### fill in result with data from each file
if args.verbose:
    print('mapping data into final array')

for source in samples.keys():
    d = data[source]
    c = columns[source]
    r = refinds[source]

    indmap = dict((tuple(val), i) for i, val in enumerate(d[:,r])) ### map to look-up columns

    d = d[:,[_ for _ in range(len(c)) if _ not in r]] ### keep only the columns that are not the reference column
    for col in args.reference_columns:
        c.remove(col)
    Ncol = len(c)

    header += c

    for ind, val in enumerate(result[:,result_refind]):
       result[ind,N:N+Ncol] = d[indmap[tuple(val)],:]

    N += Ncol ### increment

#------------------------

if args.verbose:
    print('writing collated results into: '+args.output)
np.savetxt(args.output, result, delimiter=',', comments='', header=','.join(header))
