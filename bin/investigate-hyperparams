#!/usr/bin/env python

__doc__ = "a script that lets users investigate hyperparameters and different optimization/marginalization techniques"
__author__ = "reed.essick@ligo.org"

#-------------------------------------------------

import os

import numpy as np

from argparse import ArgumentParser

### non-standard libraries
from universality import gaussianprocess as gp
from universality import hyperparams as hp
from universality import utils
from universality import plot

#-------------------------------------------------

parser = ArgumentParser(description=__doc__)

parser.add_argument('xcolumn', type=str)
parser.add_argument('ycolumn', type=str)
parser.add_argument('eospath', type=str)

parser.add_argument('-v', '--verbose', default=False, action='store_true')

parser.add_argument('--poly-degree', default=1, type=int)

parser.add_argument('--logcolumn', default=[], action='append', type=str)
parser.add_argument('--column-range', nargs=3, type=str, action='append')

parser.add_argument('--min-sigma', default=hp.DEFAULT_MIN_SIGMA, type=float,
    help='DEFAULT=%.3f'%hp.DEFAULT_MIN_SIGMA)
parser.add_argument('--max-sigma', default=hp.DEFAULT_MAX_SIGMA, type=float,
    help='DEFAULT=%.3f'%hp.DEFAULT_MAX_SIGMA)

parser.add_argument('--min-l', default=hp.DEFAULT_MIN_L, type=float,
    help='DEFAULT=%.3f'%hp.DEFAULT_MIN_L)
parser.add_argument('--max-l', default=hp.DEFAULT_MAX_L, type=float,
    help='DEFAULT=%.3f'%hp.DEFAULT_MAX_L)

parser.add_argument('--min-sigma_obs', default=hp.DEFAULT_MIN_SIGMA, type=float,
    help='DEFAULT=%.3f'%hp.DEFAULT_MIN_SIGMA)
parser.add_argument('--max-sigma_obs', default=hp.DEFAULT_MAX_SIGMA, type=float,
    help='DEFAULT=%.3f'%hp.DEFAULT_MAX_SIGMA)

parser.add_argument('--num-grid', default=gp.DEFAULT_NUM, type=int,
    help='the number of grid points in each dimension. \
DEFAULT=%d'%gp.DEFAULT_NUM)

parser.add_argument('--num-mcmc', default=hp.DEFAULT_NUM_MCMC, type=int,
    help='the number of samples to draw in mcmc. \
DEFAULT=%d'%hp.DEFAULT_NUM_MCMC)

parser.add_argument('--num-walkers', default=hp.DEFAULT_NUM_WALKERS, type=int,
    help='DEFAULT=%d'%hp.DEFAULT_NUM_WALKERS)

parser.add_argument('--maxL-method', default=hp.DEFAULT_METHOD, type=str,
    help='DEFAULT=%s'%hp.DEFAULT_METHOD)

parser.add_argument('--maxL-tol', default=hp.DEFAULT_TOL, type=float,
    help='DEFAULT=%s'%hp.DEFAULT_TOL)

parser.add_argument('--l-prior', default=hp.DEFAULT_L_PRIOR, type=str)
parser.add_argument('--sigma-prior', default=hp.DEFAULT_SIGMA_PRIOR, type=str)
parser.add_argument('--sigma_obs-prior', default=hp.DEFAULT_SIGMA_PRIOR, type=str)

parser.add_argument('--grid', default=False, action='store_true')
parser.add_argument('--mcmc', default=False, action='store_true')
parser.add_argument('--maxL', default=False, action='store_true')

parser.add_argument('--strip-mcmc', default=0, type=int,
    help='the number of burn in samples to reject from the mcmc sampler')

parser.add_argument('--num-proc', default=utils.DEFAULT_NUM_PROC, type=int)

parser.add_argument('--log-sigmas', default=False, action='store_true')
parser.add_argument('--include-logL', default=False, action='store_true')
parser.add_argument('-o', '--output-dir', default='.', type=str)
parser.add_argument('-t', '--tag', default='', type=str)

args = parser.parse_args()

assert np.any((args.grid, args.mcmc, args.maxL)), 'please specify at least one of --grid, --mcmc, --maxL'

xcolumn, ycolumn = columns = [args.xcolumn, args.ycolumn]

if args.tag:
    args.tag = "_"+args.tag

if not os.path.exists(args.output_dir):
    os.makedirs(args.output_dir)

ranges = dict((col, (float(m), float(M))) for col, m, M in args.column_range)
for col, (m, M) in ranges.items():
    if col in args.logcolumn:
        ranges[col] = (np.log(m), np.log(M))

include = np.ones(4 if args.include_logL else 3, dtype=bool)
if args.min_sigma==args.max_sigma:
    include[0] = False
if args.min_l==args.max_l:
    include[1] = False
if args.min_sigma_obs==args.max_sigma_obs:
    include[2] = False


#-------------------------------------------------

if args.verbose:
    print('reading: '+args.eospath)
data, cols = utils.load(args.eospath, columns, logcolumns=args.logcolumn)
N = len(data)
if args.verbose:
    print('found %d observations'%N)
truth = np.ones(N, dtype=bool)

x_obs = data[:,0]
if ranges.has_key(args.xcolumn):
    m, M = ranges[args.xcolumn]
    if args.verbose:
        print('retaining %s within [%.3f, %.3f]'%(cols[0], m, M))
    truth *= (m<=x_obs)*(x_obs<=M)

f_obs = data[:,1]
if ranges.has_key(args.ycolumn):
    m, M = ranges[args.ycolumn]
    if args.verbose:
        print('retaining %s within [%.3f, %.3f]'%(cols[1], m, M))
    truth *= (m<=f_obs)*(f_obs<=M)

x_obs = x_obs[truth]
f_obs = f_obs[truth]

if args.verbose:
    print('retained %d observations'%np.sum(truth))

#--- now do some logLikelihood stuff!

overlayfig = None

if args.log_sigmas:
    labels = ['$\log_{10}\sigma$', '$l$', '$\log_{10}\sigma_\mathrm{obs}$']
else:
    labels = ['$\sigma$', '$l$', '$\sigma_\mathrm{obs}$']
if args.include_logL:
    labels.append('$\log\mathcal{L}$')
labels = np.array(labels)

if args.maxL:
    if args.verbose:
        print('finding maxLikelihood with method=%s'%args.maxL_method)

    maxL = hp.logLike_maxL(
        f_obs,
        x_obs,
        (args.min_sigma, args.max_sigma),
        (args.min_l, args.max_l),
        (args.min_sigma_obs, args.max_sigma_obs),
        method=args.maxL_method,
        tol=args.maxL_tol,
        degree=args.poly_degree,
    )
    print '''\
sigma = %.3e
l     = %.3f
sigma_obs = %.3e
logL = %.3e'''%tuple(maxL[0])

    ### add to overlay plot
    if args.log_sigmas:
        truths = [np.log10(maxL['sigma'][0]), maxL['l'][0], np.log10(maxL['sigma_obs'][0])]
    else:
        truths = [maxL['sigma'][0], maxL['l'][0], maxL['sigma_obs'][0]]

    if args.include_logL:
        truths.append(maxL['logLike'][0])

    truths = np.array(truths)

else:
    truths = None

#---

if args.grid:
    if args.verbose:
        print('evaluating on a %s grid'%("x".join('%d'%args.num_grid for _ in xrange(np.sum(include)-args.include_logL))))

    grid = hp.logLike_grid(
        f_obs,
        x_obs,
        (args.min_sigma, args.max_sigma),
        (args.min_l, args.max_l),
        (args.min_sigma_obs, args.max_sigma_obs),
        num_sigma=args.num_grid,
        num_l=args.num_grid,
        num_sigma_obs=args.num_grid,
        l_prior=args.l_prior,
        sigma_prior=args.sigma_prior,
        sigma_obs_prior=args.sigma_obs_prior,
        degree=args.poly_degree,
        num_proc=args.num_proc,
    )
    path = "%s/investigate_bandwidth-grid%s.csv"%(args.output_dir, args.tag)
    if args.verbose:
        print('writing: '+path)
    tmp = ','.join('%.9e' for _ in grid.dtype.names)
    with open(path, 'w') as file_obj:
        print >> file_obj, ','.join(grid.dtype.names)
        for sample in grid:
            print >> file_obj, tmp%tuple(sample)

    if args.include_logL:
        if args.log_sigmas:
            data = np.transpose([np.log10(grid['sigma']), grid['l'], np.log10(grid['sigma_obs']), grid['logLike']])
        else:
            data = np.transpose([grid['sigma'], grid['l'], grid['sigma_obs'], grid['logLike']])
    else:
        if args.log_sigmas:
            data = np.transpose([np.log10(grid['sigma']), grid['l'], np.log10(grid['sigma_obs'])])
        else:
            data = np.transpose([grid['sigma'], grid['l'], grid['sigma_obs']])

    weights = np.exp(grid['logLike']-np.max(grid['logLike']))
    weights /= np.sum(weights)

    truth = weights>1e-2/len(weights)

    if args.verbose:
        print('    plotting')

    fig = plot.corner(
        data[truth][:,include],
        labels=labels[include],
        weights=weights[truth],
        truths=truths[include] if truths is not None else None,
        color='b',
    )
    figname = '%s/investigate_hyperparams-grid%s.png'%(args.output_dir, args.tag)
    if args.verbose:
        print('    saving: '+figname)
    fig.savefig(figname)
    plot.plt.close(fig)

    ### add to overlay plot
    overlayfig = plot.corner(
        data[truth][:,include],
        labels=labels[include],
        weights=weights[truth],
        color='b',
        truths=truths[include] if truths is not None else None,
        fig=overlayfig,
    )

#---

if args.mcmc:
    if args.verbose:
        print('running MCMC for %d steps with %d walkers'%(args.num_mcmc, args.num_walkers))

    mcmc = hp.logLike_mcmc(
        f_obs,
        x_obs,
        (args.min_sigma, args.max_sigma),
        (args.min_l, args.max_l),
        (args.min_sigma_obs, args.max_sigma_obs),
        num_samples=args.num_mcmc,
        num_walkers=args.num_walkers,
        l_prior=args.l_prior,
        sigma_prior=args.sigma_prior,
        sigma_obs_prior=args.sigma_obs_prior,
        degree=args.poly_degree,
    )
    if args.verbose:
        print('discarding %d samples as burn in'%args.strip_mcmc)
    mcmc = mcmc[args.strip_mcmc:]

    path = "%s/investigate_bandwidth-mcmc%s.csv"%(args.output_dir, args.tag)
    if args.verbose:
        print('writing: '+path)
    tmp = ','.join('%.9e' for _ in mcmc.dtype.names)
    with open(path, 'w') as file_obj:
        print >> file_obj, ','.join(mcmc.dtype.names)
        for sample in mcmc:
            print >> file_obj, tmp%tuple(sample)

    if args.include_logL:
        if args.log_sigmas:
            data = np.transpose([np.log10(mcmc['sigma']), mcmc['l'], np.log10(mcmc['sigma_obs']), mcmc['logLike']])
        else:
            data = np.transpose([mcmc['sigma'], mcmc['l'], mcmc['sigma_obs'], mcmc['logLike']])
    else:
        if args.log_sigmas:
            data = np.transpose([np.log10(mcmc['sigma']), mcmc['l'], np.log10(mcmc['sigma_obs'])])
        else:
            data = np.transpose([mcmc['sigma'], mcmc['l'], mcmc['sigma_obs']])

    if args.verbose:
        print('    plotting')
    fig = plot.corner(
        data[:,include],
        labels=labels[include],
        truths=truths[include],
        color='r',
    )
    figname = '%s/investigate_hyperparams-mcmc%s.png'%(args.output_dir, args.tag)
    if args.verbose:
        print('    saving: '+figname)
    fig.savefig(figname)
    plot.plt.close(fig)

    N = len(data)
    weights = np.ones(N, dtype='float')/N

    ### add to overlay plot
    overlayfig = plot.corner(
        data[:,include],
        labels=labels[include],
        weights=weights,
        color='r',
        truths=truths[include] if truths is not None else None,
        fig=overlayfig,
    )

#--- wrap up overlay plot

if overlayfig:
    figname = '%s/investigate_hyperparams%s.png'%(args.output_dir, args.tag)
    if args.verbose:
        print('saving: '+figname)
    overlayfig.savefig(figname)
    plot.plt.close(overlayfig)
